{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 2443,
     "status": "ok",
     "timestamp": 1689861003198,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "pPXnpT1R8Mo1"
   },
   "source": [
    "# Environment and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "hard_label_weight=0.75\n",
    "DS_weight=0.5\n",
    "DI_weight=0.5\n",
    "T=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 427,
     "status": "ok",
     "timestamp": 1689861020630,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "gNiBJ2ks86Ks"
   },
   "outputs": [],
   "source": [
    "# OS and system path\n",
    "import os\n",
    "os.chdir(\"C:/Users/kxchen/Desktop/Yuyang/multi-modality-20230721T022352Z-001/multi-modality/endovis18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1689861020630,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "lhr6LKkg9ezN"
   },
   "outputs": [],
   "source": [
    "# OS and system path\n",
    "import sys\n",
    "sys.path.append('C:/Users/kxchen/Desktop/Yuyang/multi-modality-20230721T022352Z-001/multi-modality/endovis18/Surgical_VQA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1689861025803,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "hdJKywmN9vL-"
   },
   "outputs": [],
   "source": [
    "#Warning related \n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kxchen\\.conda\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Environments\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from lib2to3.pytree import convert\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data  import DataLoader\n",
    "from utils import *\n",
    "from dataloaders.dataloaderClassification import *\n",
    "from models.VisualBertClassification import VisualBertClassification\n",
    "from models.VisualBertResMLPClassification import VisualBertResMLPClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1689861027025,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "34DLKrvN9vOO"
   },
   "outputs": [],
   "source": [
    "# functions to be used later\n",
    "def seed_everything(seed=27):\n",
    "    '''\n",
    "    Set random seed for reproducible experiments\n",
    "    Inputs: seed number\n",
    "    '''\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def train(args, train_dataloader, model, criterion, optimizer, epoch, tokenizer, device):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    label_true = None\n",
    "    label_pred = None\n",
    "    label_score = None\n",
    "\n",
    "    for i, (_, visual_features, q, labels) in enumerate(train_dataloader,0):\n",
    "\n",
    "        # prepare questions\n",
    "        questions = []\n",
    "        for question in q: questions.append(question)\n",
    "        inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
    "\n",
    "\n",
    "        # GPU / CPU\n",
    "        visual_features = visual_features.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs, visual_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)\n",
    "        label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n",
    "        label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n",
    "        label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n",
    "\n",
    "    # loss and acc\n",
    "    acc, c_acc = calc_acc(label_true, label_pred), calc_classwise_acc(label_true, label_pred)\n",
    "    precision, recall, fscore = calc_precision_recall_fscore(label_true, label_pred)\n",
    "    print('Train: epoch: %d loss: %.6f | Acc: %.6f | Precision: %.6f | Recall: %.6f | FScore: %.6f' %(epoch, total_loss, acc, precision, recall, fscore))\n",
    "    return acc\n",
    "\n",
    "\n",
    "def validate(args, val_loader, model, criterion, epoch, tokenizer, device, save_output = False):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    label_true = None\n",
    "    label_pred = None\n",
    "    label_score = None\n",
    "    file_names = list()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (file_name, visual_features, q, labels) in enumerate(val_loader,0):\n",
    "            # prepare questions\n",
    "            questions = []\n",
    "            for question in q: questions.append(question)\n",
    "            inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
    "\n",
    "            # GPU / CPU\n",
    "            visual_features = visual_features.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs, visual_features)\n",
    "            loss = criterion(outputs,labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)\n",
    "            label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n",
    "            label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n",
    "            label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n",
    "            for f in file_name: file_names.append(f)\n",
    "\n",
    "    acc = calc_acc(label_true, label_pred)\n",
    "    c_acc = 0.0\n",
    "    precision, recall, fscore = calc_precision_recall_fscore(label_true, label_pred)\n",
    "\n",
    "    print('Test: epoch: %d loss: %.6f | Acc: %.6f | Precision: %.6f | Recall: %.6f | FScore: %.6f' %(epoch, total_loss, acc, precision, recall, fscore))\n",
    "\n",
    "    if save_output:\n",
    "        '''\n",
    "            Saving predictions\n",
    "        '''\n",
    "        if os.path.exists(args.checkpoint_dir + 'text_files') == False:\n",
    "            os.mkdir(args.checkpoint_dir + 'text_files' )\n",
    "        file1 = open(args.checkpoint_dir + 'text_files/labels.txt', 'w')\n",
    "        file1.write(str(label_true))\n",
    "        file1.close()\n",
    "\n",
    "        file1 = open(args.checkpoint_dir + 'text_files/predictions.txt', 'w')\n",
    "        file1.write(str(label_pred))\n",
    "        file1.close()\n",
    "\n",
    "        if args.dataset_type == 'med_vqa':\n",
    "            if args.dataset_cat == 'cat1':\n",
    "                convert_arr = ['cta - ct angiography', 'no', 'us - ultrasound', 'xr - plain film', 'noncontrast', 'yes', 't2', 'ct w/contrast (iv)', 'mr - flair', 'mammograph', 'ct with iv contrast',\n",
    "                            'gi and iv', 't1', 'mr - t2 weighted', 'mr - t1w w/gadolinium', 'contrast', 'iv', 'an - angiogram', 'mra - mr angiography/venography', 'nm - nuclear medicine', 'mr - dwi diffusion weighted',\n",
    "                            'ct - gi & iv contrast', 'ct noncontrast', 'mr - other pulse seq.', 'ct with gi and iv contrast', 'flair', 'mr - t1w w/gd (fat suppressed)', 'ugi - upper gi', 'mr - adc map (app diff coeff)',\n",
    "                            'bas - barium swallow', 'pet - positron emission', 'mr - pdw proton density', 'mr - t1w - noncontrast', 'be - barium enema', 'us-d - doppler ultrasound', 'mr - stir', 'mr - flair w/gd',\n",
    "                            'ct with gi contrast', 'venogram', 'mr t2* gradient,gre,mpgr,swan,swi', 'mr - fiesta', 'ct - myelogram', 'gi', 'sbft - small bowel', 'pet-ct fusion']\n",
    "            elif args.dataset_cat == 'cat2':\n",
    "                convert_arr = ['axial', 'longitudinal', 'coronal', 'lateral', 'ap', 'sagittal', 'mammo - mlo', 'pa', 'mammo - cc', 'transverse', 'mammo - mag cc', 'frontal', 'oblique', '3d reconstruction', 'decubitus', 'mammo - xcc']\n",
    "            else:\n",
    "                convert_arr = ['lung, mediastinum, pleura', 'skull and contents', 'genitourinary', 'spine and contents', 'musculoskeletal', 'heart and great vessels', 'vascular and lymphatic', 'gastrointestinal', 'face, sinuses, and neck', 'breast']\n",
    "        elif args.dataset_type == 'c80':\n",
    "            convert_arr = ['no', 'calot triangle dissection', 'yes', '1', '2', 'gallbladder dissection',\n",
    "                            'clipping cutting', 'gallbladder retraction', '0', 'cleaning coagulation',\n",
    "                            'gallbladder packaging', 'preparation', '3']\n",
    "        elif args.dataset_type == 'm18':\n",
    "            convert_arr = ['kidney', 'Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation',\n",
    "                            'Tool_Manipulation', 'Cutting', 'Cauterization', 'Suction',\n",
    "                            'Looping', 'Suturing', 'Clipping', 'Staple', 'Ultrasound_Sensing',\n",
    "                            'left-top', 'right-top', 'left-bottom', 'right-bottom']\n",
    "\n",
    "        df = pd.DataFrame(columns=[\"Img\", \"Ground Truth\", \"Prediction\"])\n",
    "        for i in range(len(label_true)):\n",
    "            df = df.append({'Img': file_names[i], 'Ground Truth': convert_arr[label_true[i]], 'Prediction': convert_arr[label_pred[i]]}, ignore_index=True)\n",
    "\n",
    "        df.to_csv(args.checkpoint_dir + args.checkpoint_dir.split('/')[1] + '_' + args.checkpoint_dir.split('/')[2] + '_eval.csv')\n",
    "\n",
    "    return (acc, c_acc, precision, recall, fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1689861031993,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "Oy6LTj2Chx6y"
   },
   "outputs": [],
   "source": [
    "# functions to be used later\n",
    "def validate_18(args, val_loader, model, criterion, epoch, tokenizer, device, save_output = False):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    label_true = None\n",
    "    label_pred = None\n",
    "    label_score = None\n",
    "    file_names = list()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (file_name, visual_features, q, labels, _) in enumerate(val_loader,0):\n",
    "            # prepare questions\n",
    "            questions = []\n",
    "            for question in q: questions.append(question)\n",
    "            inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
    "\n",
    "            # GPU / CPU\n",
    "            visual_features = visual_features.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs, visual_features)\n",
    "            loss = criterion(outputs,labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)\n",
    "            label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n",
    "            label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n",
    "            label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n",
    "            for f in file_name: file_names.append(f)\n",
    "\n",
    "    acc = calc_acc(label_true, label_pred)\n",
    "    c_acc = 0.0\n",
    "    precision, recall, fscore = calc_precision_recall_fscore(label_true, label_pred)\n",
    "\n",
    "    print('Test: epoch: %d loss: %.6f | Acc: %.6f | Precision: %.6f | Recall: %.6f | FScore: %.6f' %(epoch, total_loss, acc, precision, recall, fscore))\n",
    "\n",
    "    if save_output:\n",
    "        '''\n",
    "            Saving predictions\n",
    "        '''\n",
    "        if os.path.exists(args.checkpoint_dir + 'text_files') == False:\n",
    "            os.mkdir(args.checkpoint_dir + 'text_files' )\n",
    "        file1 = open(args.checkpoint_dir + 'text_files/labels.txt', 'w')\n",
    "        file1.write(str(label_true))\n",
    "        file1.close()\n",
    "\n",
    "        file1 = open(args.checkpoint_dir + 'text_files/predictions.txt', 'w')\n",
    "        file1.write(str(label_pred))\n",
    "        file1.close()\n",
    "\n",
    "        if args.dataset_type == 'med_vqa':\n",
    "            if args.dataset_cat == 'cat1':\n",
    "                convert_arr = ['cta - ct angiography', 'no', 'us - ultrasound', 'xr - plain film', 'noncontrast', 'yes', 't2', 'ct w/contrast (iv)', 'mr - flair', 'mammograph', 'ct with iv contrast',\n",
    "                            'gi and iv', 't1', 'mr - t2 weighted', 'mr - t1w w/gadolinium', 'contrast', 'iv', 'an - angiogram', 'mra - mr angiography/venography', 'nm - nuclear medicine', 'mr - dwi diffusion weighted',\n",
    "                            'ct - gi & iv contrast', 'ct noncontrast', 'mr - other pulse seq.', 'ct with gi and iv contrast', 'flair', 'mr - t1w w/gd (fat suppressed)', 'ugi - upper gi', 'mr - adc map (app diff coeff)',\n",
    "                            'bas - barium swallow', 'pet - positron emission', 'mr - pdw proton density', 'mr - t1w - noncontrast', 'be - barium enema', 'us-d - doppler ultrasound', 'mr - stir', 'mr - flair w/gd',\n",
    "                            'ct with gi contrast', 'venogram', 'mr t2* gradient,gre,mpgr,swan,swi', 'mr - fiesta', 'ct - myelogram', 'gi', 'sbft - small bowel', 'pet-ct fusion']\n",
    "            elif args.dataset_cat == 'cat2':\n",
    "                convert_arr = ['axial', 'longitudinal', 'coronal', 'lateral', 'ap', 'sagittal', 'mammo - mlo', 'pa', 'mammo - cc', 'transverse', 'mammo - mag cc', 'frontal', 'oblique', '3d reconstruction', 'decubitus', 'mammo - xcc']\n",
    "            else:\n",
    "                convert_arr = ['lung, mediastinum, pleura', 'skull and contents', 'genitourinary', 'spine and contents', 'musculoskeletal', 'heart and great vessels', 'vascular and lymphatic', 'gastrointestinal', 'face, sinuses, and neck', 'breast']\n",
    "        elif args.dataset_type == 'c80':\n",
    "            convert_arr = ['no', 'calot triangle dissection', 'yes', '1', '2', 'gallbladder dissection',\n",
    "                            'clipping cutting', 'gallbladder retraction', '0', 'cleaning coagulation',\n",
    "                            'gallbladder packaging', 'preparation', '3']\n",
    "        elif args.dataset_type == 'm18':\n",
    "            convert_arr = ['kidney', 'Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation',\n",
    "                            'Tool_Manipulation', 'Cutting', 'Cauterization', 'Suction',\n",
    "                            'Looping', 'Suturing', 'Clipping', 'Staple', 'Ultrasound_Sensing',\n",
    "                            'left-top', 'right-top', 'left-bottom', 'right-bottom']\n",
    "\n",
    "        df = pd.DataFrame(columns=[\"Img\", \"Ground Truth\", \"Prediction\"])\n",
    "        for i in range(len(label_true)):\n",
    "            df = df.append({'Img': file_names[i], 'Ground Truth': convert_arr[label_true[i]], 'Prediction': convert_arr[label_pred[i]]}, ignore_index=True)\n",
    "\n",
    "        df.to_csv(args.checkpoint_dir + args.checkpoint_dir.split('/')[1] + '_' + args.checkpoint_dir.split('/')[2] + '_eval.csv')\n",
    "\n",
    "    return (acc, c_acc, precision, recall, fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1689861035721,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "0fnLvtCt94V1"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='VisualQuestionAnswerClassification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1689861036142,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "3YtNNqp4Bmxd",
    "outputId": "bc9b3fa0-72b9-49a5-8d8d-85a09e098ad0"
   },
   "outputs": [],
   "source": [
    "parser.add_argument('--emb_dim',        type=int,   default=300,                                help='dimension of word embeddings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1689861036143,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "wUKH05QrBm0V",
    "outputId": "f874c007-73f0-42b0-9d49-fdbb4be1cb70"
   },
   "outputs": [],
   "source": [
    "parser.add_argument('--n_heads',        type=int,   default=8,                                  help='Multi-head attention.')\n",
    "parser.add_argument('--dropout',        type=float, default=0.1,                                help='dropout')\n",
    "parser.add_argument('--encoder_layers', type=int,   default=6,                                  help='the number of layers of encoder in Transformer.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1689861038310,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "rUkuYH5dBm2j",
    "outputId": "33d0a7db-89e5-48f3-9718-c808007ed955"
   },
   "outputs": [],
   "source": [
    "    # Training parameters\n",
    "    parser.add_argument('--epochs',         type=int,   default=80,                                 help='number of epochs to train for (if early stopping is not triggered).') #80, 26\n",
    "    parser.add_argument('--batch_size',     type=int,   default=64,                                 help='batch_size')\n",
    "    parser.add_argument('--workers',        type=int,   default=1,                                  help='for data-loading; right now, only 1 works with h5pys.')\n",
    "    parser.add_argument('--print_freq',     type=int,   default=100,                                help='print training/validation stats every __ batches.')\n",
    "\n",
    "    # existing checkpoint\n",
    "    parser.add_argument('--checkpoint',     default=None,                                           help='path to checkpoint, None if none.')\n",
    "\n",
    "    parser.add_argument('--lr',             type=float, default=0.00001,                            help='0.000005, 0.00001, 0.000005')\n",
    "    parser.add_argument('--checkpoint_dir', default= '/content/drive/MyDrive/Colab Notebooks/research/multi-modality/svqa/checkpoints/18/',    help='med_vqa_c$version$/m18/c80//m18_vid$temporal_size$/c80_vid$temporal_size$') #clf_v1_2_1x1/med_vqa_c3\n",
    "    parser.add_argument('--dataset_type',   default= 'm18',                                     help='med_vqa/m18/c80/m18_vid/c80_vid')\n",
    "    parser.add_argument('--dataset_cat',    default= 'None',                                        help='cat1/cat2/cat3')\n",
    "    parser.add_argument('--transformer_ver',default= 'vbrm',                                        help='vb/vbrm')\n",
    "    parser.add_argument('--tokenizer_ver',  default= 'v2',                                          help='v2/v3')\n",
    "    parser.add_argument('--patch_size',     default= 5,                                             help='1/2/3/4/5')\n",
    "    parser.add_argument('--temporal_size',  default= 3,                                             help='1/2/3/4/5')\n",
    "    parser.add_argument('--question_len',   default= 25,                                            help='25')\n",
    "    parser.add_argument('--num_class',      default= 2,                                             help='25')\n",
    "    parser.add_argument('--validate',       default=False,                                          help='When only validation required False/True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1689861039229,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "927spLAMCdd-",
    "outputId": "4f63939b-074e-4093-9c6b-30f9a8a27cf6"
   },
   "outputs": [],
   "source": [
    "parser.add_argument('-f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1689861040109,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "BVYPeC_bBm4_"
   },
   "outputs": [],
   "source": [
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1689861040110,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "qT2E7aBP94YS"
   },
   "outputs": [],
   "source": [
    "# load checkpoint, these parameters can't be modified\n",
    "final_args = {\"emb_dim\": 300, \"n_heads\": 8, \"dropout\": 0.1, \"encoder_layers\": 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1689861040895,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "k3p_qRlO9vRA"
   },
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1689861041368,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "VUVcmH4N-md_",
    "outputId": "1b70356e-7b13-40cf-e8cd-53e697e3ac53"
   },
   "outputs": [],
   "source": [
    "# GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n",
    "cudnn.benchmark = True  # set to true only if inputs to model are fixed size; otherwise lot of computational overhead\n",
    "print('device =', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1689861044303,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "AtPTsnSQ-mgo"
   },
   "outputs": [],
   "source": [
    "# best model initialize\n",
    "start_epoch = 1\n",
    "best_epoch = [0]\n",
    "best_results = [0.0]\n",
    "epochs_since_improvement = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1862,
     "status": "ok",
     "timestamp": 1689861047565,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "bmnCO1QF-vyO"
   },
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "tokenizer = None\n",
    "tokenizer = BertTokenizer.from_pretrained(\"C:/Users/kxchen/Desktop/Yuyang/multi-modality-20230721T022352Z-001/multi-modality/endovis18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1689861047566,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "2Dd9-TLsuoji",
    "outputId": "c178ae88-f15e-4aea-f46f-cad7f124bb55"
   },
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1689861049558,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "cIwCR9dq3Qiy"
   },
   "outputs": [],
   "source": [
    "args.num_class = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3110,
     "status": "ok",
     "timestamp": 1689861053109,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "2vyvuuaT_z2r"
   },
   "outputs": [],
   "source": [
    "#if args.transformer_ver == 'vb':\n",
    "model = VisualBertClassification(vocab_size=len(tokenizer), layers=6, n_heads=8, num_class = args.num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1689861053109,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "TQnFnWfWZ4H8"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6221,
     "status": "ok",
     "timestamp": 1689861059328,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "6yvL-Q5W3QlW",
    "outputId": "f94118c9-a620-4490-a811-ea5c3ead7517"
   },
   "outputs": [],
   "source": [
    "# Move to GPU, if available\n",
    "model = model.to(device)\n",
    "print(final_args)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print('model params: ', pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1689861059328,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "9aAArwAoAn8B"
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate imbalance ratio (IR) for the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question2tool_18(question):\n",
    "    question = question.strip('?') # remove the question mark\n",
    "    split = question.split()\n",
    "    tool = 'error'\n",
    "    for i in range(len(split)):\n",
    "        if split[i] in instrument_18:\n",
    "            tool = split[i]\n",
    "\n",
    "    return tool\n",
    "\n",
    "instrument_18 = ['bipolar_forceps','prograsp_forceps','monopolar_curved_scissors','ultrasound_probe','large_needle_driver','suction','clip_applier','stapler']\n",
    "\n",
    "def question2tool_17(question):\n",
    "    question = question.strip('?') # remove the question mark\n",
    "    split = question.split()\n",
    "    tool = 'error'\n",
    "    for i in range(len(split)):\n",
    "        if split[i] in instrument_17:\n",
    "            tool = split[i]\n",
    "    \n",
    "    return tool\n",
    "\n",
    "instrument_17 = ['bipolar_forceps','prograsp_forceps','monopolar_curved_scissors','ultrasound_probe','large_needle_driver']\n",
    "\n",
    "def question2tool_DAISI(question):\n",
    "    question = question.strip('?') # remove the question mark\n",
    "    split = question.split()\n",
    "    tool = split[-1]\n",
    "    return tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = np.arange(1,380).tolist()\n",
    "val_seq = np.arange(380,475).tolist()\n",
    "\n",
    "folder_head = 'C:/Users/kxchen/Desktop/Yuyang/multi-modality-20230721T022352Z-001/multi-modality/new_data_daisi/seq_'\n",
    "folder_tail = '/vqa/*.txt'\n",
    "\n",
    "train_dataset = DAISI_VQA(train_seq, folder_head, folder_tail, patch_size = 5)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size= 1, shuffle=True)\n",
    "val_dataset = DAISI_VQA(val_seq, folder_head, folder_tail, patch_size = 5)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size= 1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = []\n",
    "a = []\n",
    "\n",
    "for i in range(len(train_dataset.vqas)):\n",
    "    q.append(train_dataset.vqas[i][1].split('|')[0])\n",
    "    a.append(train_dataset.vqas[i][1].split('|')[1])\n",
    "    \n",
    "from pandas.core.frame import DataFrame\n",
    "\n",
    "c={\"question\" : q,\n",
    "   \"answer\" : a}# transform to dictionary\n",
    "data_daisi=DataFrame(c)# transform to data frame\n",
    "\n",
    "for i in range(len(data_daisi)):\n",
    "    data_daisi.at[i,'q_type'] = question2tool_DAISI(data_daisi.at[i,'question'])\n",
    "\n",
    "data_daisi['type'] = 'daisi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_daisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = [2, 3, 4, 6, 7, 9, 10, 11, 12, 14, 15]\n",
    "val_seq = [1, 5, 16]\n",
    "\n",
    "folder_head = 'C:/Users/kxchen/Desktop/Yuyang/multi-modality-20230721T022352Z-001/multi-modality/endovis18/seq_'\n",
    "folder_tail = '/vqa/Classification_t5_loss/*.txt'\n",
    "\n",
    "train_dataset = EndoVis18VQAClassification(train_seq, folder_head, folder_tail, patch_size = 5)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size= 1, shuffle=True)\n",
    "\n",
    "val_dataset = EndoVis18VQAClassification(val_seq, folder_head, folder_tail, patch_size = 5)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size= 1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = []\n",
    "a = []\n",
    "\n",
    "for i in range(len(train_dataset.vqas)):\n",
    "    q.append(train_dataset.vqas[i][1].split('|')[0])\n",
    "    a.append(train_dataset.vqas[i][1].split('|')[1])\n",
    "    \n",
    "from pandas.core.frame import DataFrame\n",
    "\n",
    "c={\"question\" : q,\n",
    "   \"answer\" : a}# transform to dictionary\n",
    "data=DataFrame(c)# transform to data frame\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data.at[i,'q_type'] = question2tool_18(data.at[i,'question'])\n",
    "\n",
    "data['type'] = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = [1,2,6,9]\n",
    "val_seq = [8]\n",
    "\n",
    "folder_head = 'C:/Users/kxchen/Desktop/Yuyang/multi-modality-20230721T022352Z-001/multi-modality/endovis17/seq_'\n",
    "folder_tail = '/vqa/*.txt'\n",
    "\n",
    "train_dataset = EndoVis17VQAClassification(train_seq, folder_head, folder_tail, patch_size = 5)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size= 64, shuffle=True)\n",
    "val_dataset = EndoVis17VQAClassification(val_seq, folder_head, folder_tail, patch_size = 5)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size= 64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = []\n",
    "a = []\n",
    "\n",
    "for i in range(len(train_dataset.vqas)):\n",
    "    q.append(train_dataset.vqas[i][1].split('|')[0])\n",
    "    a.append(train_dataset.vqas[i][1].split('|')[1])\n",
    "    \n",
    "from pandas.core.frame import DataFrame\n",
    "\n",
    "c={\"question\" : q,\n",
    "   \"answer\" : a}# transform to dictionary\n",
    "data_17=DataFrame(c)# transform to data frame\n",
    "\n",
    "data_17['q_type'] = ''\n",
    "for i in range(len(data_17)):\n",
    "    data_17.at[i,'q_type'] = question2tool_17(data_17.at[i,'question'])\n",
    "\n",
    "data_17['type'] = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp = data.append(data_17)\n",
    "data_tmp = data_tmp.append(data_daisi)\n",
    "data_all = data_tmp[data_tmp['q_type']!='error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "y=data_all['q_type'].value_counts().values\n",
    "x=data_all['q_type'].value_counts().index\n",
    "frequency = pd.DataFrame()\n",
    "frequency.index = x\n",
    "frequency['17+18+daisi'] = y\n",
    "\n",
    "# export\n",
    "y_17=data_all[data_all['type']==17]['q_type'].value_counts().values\n",
    "x=data_all[data_all['type']==17]['q_type'].value_counts().index\n",
    "frequency_17 = pd.DataFrame()\n",
    "frequency_17.index = x\n",
    "frequency_17['17'] = y_17\n",
    "\n",
    "# export\n",
    "y_daisi=data_all[data_all['type']=='daisi']['q_type'].value_counts().values\n",
    "x=data_all[data_all['type']=='daisi']['q_type'].value_counts().index\n",
    "frequency_daisi = pd.DataFrame()\n",
    "frequency_daisi.index = x\n",
    "frequency_daisi['daisi'] = y_daisi\n",
    "\n",
    "# export\n",
    "y_18=data_all[data_all['type']==18]['q_type'].value_counts().values\n",
    "x=data_all[data_all['type']==18]['q_type'].value_counts().index\n",
    "frequency_18 = pd.DataFrame()\n",
    "frequency_18.index = x\n",
    "frequency_18['18'] = y_18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_all = frequency.join(frequency_18).join(frequency_17).join(frequency_daisi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_all = frequency_all.fillna(0)\n",
    "frequency_all['17+18'] = frequency_all['17'] + frequency_all['18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_17_18=frequency_all['17+18'].max()\n",
    "tmp = frequency_all[['17+18']].values\n",
    "tmp1 = tmp.nonzero()\n",
    "min_17_18 = tmp[tmp1].min()\n",
    "\n",
    "max_17_18_daisi=frequency_all['17+18+daisi'].max()\n",
    "tmp = frequency_all[['17+18+daisi']].values\n",
    "tmp1 = tmp.nonzero()\n",
    "min_17_18_daisi = tmp[tmp1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IR_17_18 = max_17_18 / min_17_18\n",
    "IR_17_18_daisi = max_17_18_daisi / min_17_18_daisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "ln_IR_17_18 = math.log(IR_17_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_IR_17_18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7f00SvdC_-F"
   },
   "source": [
    "# train endovis 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 713544,
     "status": "ok",
     "timestamp": 1688908189787,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "1cbEIyyAs8_G",
    "outputId": "5dccbb48-d524-4d65-b492-df84a908edf9"
   },
   "outputs": [],
   "source": [
    "# no need to train the 17 model, as we are interested in the continual learning process\n",
    "# you can just load the checkpoint_17 model to skip the long training time\n",
    "# you can uncomment the following code if you want to train the 17 model\n",
    "'''\n",
    "train_seq = [1,2,6,9]\n",
    "val_seq = [8]\n",
    "\n",
    "folder_head = '/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis17/seq_'\n",
    "folder_tail = '/vqa/*.txt'\n",
    "\n",
    "train_dataset = EndoVis17VQAClassification(train_seq, folder_head, folder_tail, patch_size = 5)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size= 64, shuffle=True)\n",
    "val_dataset = EndoVis17VQAClassification(val_seq, folder_head, folder_tail, patch_size = 5)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size= 64, shuffle=False)\n",
    "\n",
    "\n",
    "args.checkpoint_dir = '/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18/checkpoints/17/'\n",
    "\n",
    "for epoch in range(start_epoch, 80):\n",
    "\n",
    "  if epochs_since_improvement > 0 and epochs_since_improvement % 5 == 0:\n",
    "    adjust_learning_rate(optimizer, 0.8)\n",
    "\n",
    "  # train\n",
    "  train_acc = train(args, train_dataloader=train_dataloader, model = model, criterion=criterion, optimizer=optimizer, epoch=epoch, tokenizer = tokenizer, device = device)\n",
    "\n",
    "  # validation\n",
    "  test_acc, test_c_acc, test_precision, test_recall, test_fscore = validate(args, val_loader=val_dataloader, model = model, criterion=criterion, epoch=epoch, tokenizer = tokenizer, device = device)\n",
    "\n",
    "  if test_acc >= best_results[0]:\n",
    "    epochs_since_improvement = 0\n",
    "\n",
    "    best_results[0] = test_acc\n",
    "    best_epoch[0] = epoch\n",
    "    print('Best epoch: %d | Best acc: %.6f' %(best_epoch[0], best_results[0]))\n",
    "    save_clf_checkpoint(args.checkpoint_dir, epoch, epochs_since_improvement, model, optimizer, best_results[0], final_args)\n",
    "\n",
    "  else:\n",
    "    epochs_since_improvement += 1\n",
    "    print(\"\\nEpochs since last improvement: %d\\n\" % (epochs_since_improvement,))\n",
    "\n",
    "  if train_acc >= 1.0: break\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKiQE8lcuTmv"
   },
   "source": [
    "# Load data and models for ACC test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 928972,
     "status": "ok",
     "timestamp": 1689861990064,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "yjwtRmv1s9BS",
    "outputId": "92a8e196-7b1e-472c-f43e-22387d683252"
   },
   "outputs": [],
   "source": [
    "train_seq = [2, 3, 4, 6, 7, 9, 10, 11, 12, 14, 15]\n",
    "val_seq = [1, 5, 16]\n",
    "\n",
    "folder_head = 'C:/Users/kxchen/Desktop/Yuyang/multi-modality-20230721T022352Z-001/multi-modality/endovis18/seq_'\n",
    "folder_tail = '/vqa/Classification_t5_loss/*.txt'\n",
    "\n",
    "train_dataset = EndoVis18VQAClassification(train_seq, folder_head, folder_tail, patch_size = 5)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size= 1, shuffle=True)\n",
    "\n",
    "val_dataset = EndoVis18VQAClassification(val_seq, folder_head, folder_tail, patch_size = 5)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size= 1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 62665,
     "status": "ok",
     "timestamp": 1689862054559,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "_9ZvnzF4YSOe"
   },
   "outputs": [],
   "source": [
    "# old model\n",
    "checkpoint_old = torch.load('C:/Users/kxchen/Desktop/Yuyang/multi-modality-20230721T022352Z-001/multi-modality/endovis18/ablation/checkpoints_all/17/checkpoint_17.pth.tar')\n",
    "model_old = checkpoint_old['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3115,
     "status": "ok",
     "timestamp": 1689862057671,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "Kw_RWdg8CSl2"
   },
   "outputs": [],
   "source": [
    "# new model\n",
    "checkpoint = torch.load('C:/Users/kxchen/Desktop/Yuyang/multi-modality-20230721T022352Z-001/multi-modality/endovis18/ablation/checkpoints_all/17/checkpoint_17.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1689862057671,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "8v08Uv9IBH_p"
   },
   "outputs": [],
   "source": [
    "model = checkpoint['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 642,
     "status": "ok",
     "timestamp": 1689862058310,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "j_F2mnvtBIBk"
   },
   "outputs": [],
   "source": [
    "optimizer = checkpoint['optimizer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acc of the conventional teacher and the LLM teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2list(target_str):\n",
    "  res=target_str.strip('[')\n",
    "  res=res.strip(']')\n",
    "  res=res.split(',')\n",
    "\n",
    "  for i in range(len(res)):\n",
    "    res[i] = res[i].strip() # remove the space\n",
    "\n",
    "  new_list = [float(x) for x in res]\n",
    "  return new_list[:18] # only the first 18 elements are wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the ACC of the soft target\n",
    "label = []\n",
    "label_soft_list = []\n",
    "\n",
    "for i, (_, visual_features, q, labels, t5_loss) in enumerate(train_dataloader,0):\n",
    "\n",
    "    label_number = labels.numpy()[0]\n",
    "\n",
    "    label += labels.tolist()\n",
    "\n",
    "    # prepare questions\n",
    "    questions = []\n",
    "    for question in q: questions.append(question)\n",
    "\n",
    "    inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
    "    \n",
    "    # GPU / CPU\n",
    "    visual_features = visual_features.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    soft_target = model_old(inputs, visual_features) # soft_target is the output of the conventional teacher\n",
    "    output_class_ranks = torch.argsort(soft_target, dim=-1, descending=True)\n",
    "    \n",
    "    label_soft = []\n",
    "    for j in range(len(output_class_ranks)):\n",
    "        label_soft.append(int(output_class_ranks[j][0]))\n",
    "    \n",
    "    label_soft_list += label_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.frame import DataFrame\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "\n",
    "c={\"label\" : label,\n",
    "   \"label_soft_list\" : label_soft_list}# transform to dictionary\n",
    "data=DataFrame(c)# transform to data frame\n",
    "#print(data)\n",
    "\n",
    "acc_soft = []\n",
    "\n",
    "for i in range(18):\n",
    "    label_part = []\n",
    "    label_soft_part = []\n",
    "\n",
    "    for j in range(len(data)):\n",
    "        if data.at[j,'label'] == i:\n",
    "            label_part.append(data.at[j,'label'])\n",
    "            label_soft_part.append(data.at[j,'label_soft_list'])\n",
    "\n",
    "    acc_soft.append(accuracy_score(label_part, label_soft_part))\n",
    "\n",
    "acc_soft = [0 if math.isnan(x) else x for x in acc_soft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the ACC of the LLM teacher\n",
    "label = []\n",
    "label_llm_list = []\n",
    "\n",
    "for i, (_, visual_features, q, labels, t5_loss) in enumerate(train_dataloader,0):\n",
    "  label += labels.tolist()\n",
    "\n",
    "  t5_loss_list = []\n",
    "  for j in range(len(t5_loss)):\n",
    "    tmp = str2list(t5_loss[j])\n",
    "    t5_loss_list.append(tmp)\n",
    "\n",
    "  check = np.reciprocal(t5_loss_list)\n",
    "  t5_loss_tensor = torch.tensor(check)\n",
    "  output_class_ranks = torch.argsort(t5_loss_tensor, dim=-1, descending=True)\n",
    "\n",
    "  label_llm = []\n",
    "  for j in range(len(output_class_ranks)):\n",
    "    label_llm.append(int(output_class_ranks[j][0]))\n",
    "\n",
    "  label_llm_list += label_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pandas.core.frame import DataFrame\n",
    "\n",
    "c={\"label\" : label,\n",
    "   \"label_llm_list\" : label_llm_list}# transform to dictionary\n",
    "data=DataFrame(c)# transform to data frame\n",
    "\n",
    "acc_llm = []\n",
    "\n",
    "for i in range(18):\n",
    "  label_part = []\n",
    "  label_llm_part = []\n",
    "\n",
    "  for j in range(len(data)):\n",
    "    if data.at[j,'label'] == i:\n",
    "      label_part.append(data.at[j,'label'])\n",
    "      label_llm_part.append(data.at[j,'label_llm_list'])\n",
    "\n",
    "  acc_llm.append(accuracy_score(label_part, label_llm_part))\n",
    "  #print(\"acc=\",acc_llm)\n",
    "  #print(\"len=\",len(label_part))\n",
    "  \n",
    "acc_llm = [0 if math.isnan(x) else x for x in acc_llm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c={\"acc_soft\" : acc_soft,\n",
    "   \"acc_llm\" : acc_llm}# transform to dictionary\n",
    "weight_data_17_18=DataFrame(c)# transform to data frame\n",
    "\n",
    "for i in range(len(weight_data_17_18)):\n",
    "  if weight_data_17_18.at[i,'acc_soft'] + weight_data_17_18.at[i,'acc_llm'] == 0:\n",
    "    weight_data_17_18.at[i,'DS_soft'] = 0.5*(1 - hard_label_weight)\n",
    "    weight_data_17_18.at[i,'DS_llm'] = 0.5*(1 - hard_label_weight)\n",
    "  else:\n",
    "    weight_data_17_18.at[i,'DS_soft'] = (1-hard_label_weight) * weight_data_17_18.at[i,'acc_soft'] / (weight_data_17_18.at[i,'acc_soft'] + weight_data_17_18.at[i,'acc_llm'])\n",
    "    weight_data_17_18.at[i,'DS_llm'] = (1-hard_label_weight) * weight_data_17_18.at[i,'acc_llm'] / (weight_data_17_18.at[i,'acc_soft'] + weight_data_17_18.at[i,'acc_llm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight processing\n",
    "weight_data_17_18['DI_soft']=(1-hard_label_weight) * (0.5 / (1 + IR_17_18))\n",
    "weight_data_17_18['DI_llm'] = (1-hard_label_weight) * ((0.5 + IR_17_18) / (1 + IR_17_18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_data_17_18['weight_true_label']=hard_label_weight\n",
    "\n",
    "weight_data_17_18['weight_soft'] = DS_weight * weight_data_17_18['DS_soft'] + DI_weight * weight_data_17_18['DI_soft']\n",
    "weight_data_17_18['weight_llm'] = DS_weight * weight_data_17_18['DS_llm'] + DI_weight * weight_data_17_18['DI_llm']\n",
    "\n",
    "weight_data_17_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_weight = weight_data_17_18[['weight_true_label','weight_soft','weight_llm']]\n",
    "acc_weight.weight_data_17_18 = ['weight_true_label','weight_soft','weight_llm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1689862058311,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "G6pasgluYy7R"
   },
   "source": [
    "# Train new continual learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_old = model_old.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1689862058311,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "RSi_1ViRAn_t",
    "outputId": "b2c69bfd-026b-411b-8224-f074c7ad9722"
   },
   "outputs": [],
   "source": [
    "# Move to GPU, if available\n",
    "model = model.to(device)\n",
    "print(final_args)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print('model params: ', pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1689862058313,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "2Q-X2gzGEwNn"
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1689862058313,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "d6ktZ0WwEwP1"
   },
   "outputs": [],
   "source": [
    "args.checkpoint_dir = 'C:/Users/kxchen/Desktop/Yuyang/multi-modality-20230721T022352Z-001/multi-modality/endovis18/ablation/checkpoints_all/17+18/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1689862058314,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "KAlaF1v19_pn"
   },
   "outputs": [],
   "source": [
    "# best model initialize\n",
    "start_epoch = 1\n",
    "best_epoch = [0]\n",
    "best_results = [0.0]\n",
    "epochs_since_improvement = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1689862058314,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "ZMB-7VDDaEwk"
   },
   "outputs": [],
   "source": [
    "# parameters for lwf\n",
    "T=2\n",
    "#alpha = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1689862058314,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "Eic0ech0ghWL"
   },
   "outputs": [],
   "source": [
    "out_features = model.classifier.out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1689862058314,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "ZnXYJoVI0TD4"
   },
   "outputs": [],
   "source": [
    "def str2list(target_str):\n",
    "  res=target_str.strip('[')\n",
    "  res=res.strip(']')\n",
    "  res=res.split(',')\n",
    "\n",
    "  for i in range(len(res)):\n",
    "    res[i] = res[i].strip() # remove the space\n",
    "\n",
    "  new_list = [float(x) for x in res]\n",
    "  return new_list[:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1689862058315,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "hKinQRdVaJ5S"
   },
   "outputs": [],
   "source": [
    "# training function for lwf\n",
    "def train_lwf(args, train_dataloader, model, criterion, optimizer, epoch, tokenizer, device):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    label_true = None\n",
    "    label_pred = None\n",
    "    label_score = None\n",
    "\n",
    "\n",
    "    for i, (_, visual_features, q, labels, t5_loss) in enumerate(train_dataloader,0):\n",
    "        \n",
    "        label_number = labels.numpy()[0]\n",
    "\n",
    "        # prepare questions\n",
    "        questions = []\n",
    "        for question in q: questions.append(question)\n",
    "        inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
    "\n",
    "        # t5 loss\n",
    "        t5_loss_list = []\n",
    "        for j in range(len(t5_loss)):\n",
    "          tmp = str2list(t5_loss[j])\n",
    "          t5_loss_list.append(tmp)\n",
    "        check = np.reciprocal(t5_loss_list)\n",
    "        t5_loss_tensor = torch.tensor(check)\n",
    "\n",
    "        t5_loss_tensor = t5_loss_tensor.to(device)\n",
    "\n",
    "        # GPU / CPU\n",
    "        visual_features = visual_features.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs, visual_features)\n",
    "        soft_target = model_old(inputs, visual_features)\n",
    "\n",
    "        loss1 = criterion(outputs, labels)\n",
    "\n",
    "        outputs_S = F.softmax(outputs[:,:out_features]/T,dim=1)\n",
    "        outputs_T = F.softmax(soft_target[:,:out_features]/T,dim=1)\n",
    "\n",
    "        outputs_t5_loss = F.softmax(t5_loss_tensor[:,:out_features]/T,dim=1)\n",
    "\n",
    "        loss2 = outputs_T.mul(-1*torch.log(outputs_S))\n",
    "        loss2 = loss2.sum(1)\n",
    "        loss2 = loss2.mean()*T*T\n",
    "\n",
    "        loss3 = outputs_t5_loss.mul(-1*torch.log(outputs_S))\n",
    "        loss3 = loss3.sum(1)\n",
    "        loss3 = loss3.mean()*T*T\n",
    "\n",
    "        #loss = loss1 * 0.8 + loss2 * 0.123 + loss3 * 0.077\n",
    "        loss = loss1 * acc_weight.at[label_number,'weight_true_label'] + loss2 * acc_weight.at[label_number,'weight_soft'] + loss3 * acc_weight.at[label_number,'weight_llm']\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)\n",
    "        label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n",
    "        label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n",
    "        label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n",
    "\n",
    "    # loss and acc\n",
    "    acc, c_acc = calc_acc(label_true, label_pred), calc_classwise_acc(label_true, label_pred)\n",
    "    precision, recall, fscore = calc_precision_recall_fscore(label_true, label_pred)\n",
    "    print('Train: epoch: %d loss: %.6f | Acc: %.6f | Precision: %.6f | Recall: %.6f | FScore: %.6f' %(epoch, total_loss, acc, precision, recall, fscore))\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4491813,
     "status": "error",
     "timestamp": 1689866550118,
     "user": {
      "displayName": "kexin chen",
      "userId": "10371452033462374396"
     },
     "user_tz": -480
    },
    "id": "IFjOAVaOEwSG",
    "outputId": "c298fb9a-bd77-4a20-8ce1-02511145154c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch,10):\n",
    "  if epochs_since_improvement > 0 and epochs_since_improvement % 5 == 0:\n",
    "    adjust_learning_rate(optimizer, 0.8)\n",
    "\n",
    "  # train\n",
    "  #train_acc = train(args, train_dataloader=train_dataloader, model = model, criterion=criterion, optimizer=optimizer, epoch=epoch, tokenizer = tokenizer, device = device)\n",
    "  train_acc = train_lwf(args, train_dataloader=train_dataloader, model = model, criterion=criterion, optimizer=optimizer, epoch=epoch, tokenizer = tokenizer, device = device)\n",
    "\n",
    "  # validation\n",
    "  test_acc, test_c_acc, test_precision, test_recall, test_fscore = validate_18(args, val_loader=val_dataloader, model = model, criterion=criterion, epoch=epoch, tokenizer = tokenizer, device = device)\n",
    "\n",
    "  if test_acc >= best_results[0]:\n",
    "    epochs_since_improvement = 0\n",
    "\n",
    "    best_results[0] = test_acc\n",
    "    best_epoch[0] = epoch\n",
    "    print('Best epoch: %d | Best acc: %.6f' %(best_epoch[0], best_results[0]))\n",
    "    save_clf_checkpoint(args.checkpoint_dir, epoch, epochs_since_improvement, model, optimizer, best_results[0], final_args)\n",
    "\n",
    "  else:\n",
    "    epochs_since_improvement += 1\n",
    "    print(\"\\nEpochs since last improvement: %d\\n\" % (epochs_since_improvement,))\n",
    "\n",
    "  if train_acc >= 1.0: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test the model on 17 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = [1,2,6,9]\n",
    "val_seq = [8]\n",
    "\n",
    "folder_head = 'C:/Users/kxchen/Desktop/Yuyang/multi-modality-20230721T022352Z-001/multi-modality/endovis17/seq_'\n",
    "folder_tail = '/vqa/*.txt'\n",
    "\n",
    "train_dataset = EndoVis17VQAClassification(train_seq, folder_head, folder_tail, patch_size = 5)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size= 64, shuffle=True)\n",
    "\n",
    "val_dataset = EndoVis17VQAClassification(val_seq, folder_head, folder_tail, patch_size = 5)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size= 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('C:/Users/kxchen/Desktop/Yuyang/multi-modality-20230721T022352Z-001/multi-modality/endovis18/ablation/checkpoints_all/17+18/Best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = checkpoint['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to GPU, if available\n",
    "model = model.to(device)\n",
    "print(final_args)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print('model params: ', pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "test_acc, test_c_acc, test_precision, test_recall, test_fscore = validate(args, val_loader=val_dataloader, model = model, criterion=criterion, epoch=epoch, tokenizer = tokenizer, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPsC4cA03NIaLonnoL0ZRGI",
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
