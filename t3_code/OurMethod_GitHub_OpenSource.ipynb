{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4Ob4DMIUUXC"
      },
      "outputs": [],
      "source": [
        "T=2\n",
        "N_Balance = 2000\n",
        "DS_weight=0.2\n",
        "DI_weight=0.8\n",
        "hard_label_weight=0.4\n",
        "epoch_num=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjvXse7NV23K"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WS66FegVV4_Z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18\")\n",
        "import argparse\n",
        "import pandas as pd\n",
        "from lib2to3.pytree import convert\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gLMdAW7W6oi"
      },
      "outputs": [],
      "source": [
        "pip install transformers==4.18.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npAwHewjXC-5"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "from torch.utils.data  import DataLoader\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18/Surgical_VQA')\n",
        "from utils import *\n",
        "from dataloaders.dataloaderClassification import *\n",
        "from models.VisualBertClassification import VisualBertClassification\n",
        "from models.VisualBertResMLPClassification import VisualBertResMLPClassification\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mVVTF5OZNZS"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed=27):\n",
        "    '''\n",
        "    Set random seed for reproducible experiments\n",
        "    Inputs: seed number\n",
        "    '''\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBc6hX9rZYco"
      },
      "outputs": [],
      "source": [
        "def train_17_18(args, train_dataloader, model, criterion, optimizer, epoch, tokenizer, device):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    label_true = None\n",
        "    label_pred = None\n",
        "    label_score = None\n",
        "\n",
        "\n",
        "    for i, (_, visual_features, q, labels) in enumerate(train_dataloader,0):\n",
        "\n",
        "        # prepare questions\n",
        "        questions = []\n",
        "        for question in q: questions.append(question)\n",
        "        inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
        "\n",
        "\n",
        "        # GPU / CPU\n",
        "        visual_features = visual_features.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs, visual_features)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics scores:概率值，predicted:标签\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)\n",
        "        label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n",
        "        label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n",
        "        label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n",
        "\n",
        "    # loss and acc\n",
        "    # acc：预测标签与真实标签匹配的比例，c_acc：计算每个类别的准确率。\n",
        "    # Precision（精确率）：模型预测为正的样本中实际为正的比例。\n",
        "    # Recall（召回率）：实际为正的样本中被正确预测为正的比例。\n",
        "    # F-Score：精确率和召回率的调和平均数，用于综合评价模型性能。\n",
        "    acc, c_acc = calc_acc(label_true, label_pred), calc_classwise_acc(label_true, label_pred)\n",
        "    precision, recall, fscore = calc_precision_recall_fscore(label_true, label_pred)\n",
        "    print('Train: epoch: %d loss: %.6f | Acc: %.6f | Precision: %.6f | Recall: %.6f | FScore: %.6f' %(epoch, total_loss, acc, precision, recall, fscore))\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35lhtZgoZdnW"
      },
      "outputs": [],
      "source": [
        "def validate_17_18(args, val_loader, model, criterion, epoch, tokenizer, device, save_output = False):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    label_true = None\n",
        "    label_pred = None\n",
        "    label_score = None\n",
        "    file_names = list()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    convert_arr = ['kidney', 'Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation',\n",
        "              'Tool_Manipulation', 'Cutting', 'Cauterization', 'Suction',\n",
        "               'Looping', 'Suturing', 'Clipping', 'Staple', 'Ultrasound_Sensing',\n",
        "              'left-top', 'right-top', 'left-bottom', 'right-bottom',\n",
        "                   'no', 'yes','left', 'right']\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (file_name, visual_features, q, labels) in enumerate(val_loader,0):\n",
        "            # prepare questions\n",
        "            questions = []\n",
        "            for question in q: questions.append(question)\n",
        "            inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
        "\n",
        "            # GPU / CPU\n",
        "            visual_features = visual_features.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs, visual_features)\n",
        "\n",
        "            loss = criterion(outputs,labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)\n",
        "\n",
        "            # print(predicted)\n",
        "\n",
        "            label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n",
        "            label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n",
        "            label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n",
        "            for f in file_name: file_names.append(f)\n",
        "\n",
        "    acc = calc_acc(label_true, label_pred)\n",
        "    c_acc = 0.0\n",
        "    # c_acc = calc_classwise_acc(label_true, label_pred)\n",
        "    precision, recall, fscore = calc_precision_recall_fscore(label_true, label_pred)\n",
        "\n",
        "    print('Test: epoch: %d loss: %.6f | Acc: %.6f | Precision: %.6f | Recall: %.6f | FScore: %.6f' %(epoch, total_loss, acc, precision, recall, fscore))\n",
        "\n",
        "    if save_output:\n",
        "        '''\n",
        "            Saving predictions\n",
        "        '''\n",
        "        if os.path.exists(args.checkpoint_dir + 'text_files') == False:\n",
        "            os.mkdir(args.checkpoint_dir + 'text_files' )\n",
        "        file1 = open(args.checkpoint_dir + 'text_files/labels.txt', 'w')\n",
        "        file1.write(str(label_true))\n",
        "        file1.close()\n",
        "\n",
        "        file1 = open(args.checkpoint_dir + 'text_files/predictions.txt', 'w')\n",
        "        file1.write(str(label_pred))\n",
        "        file1.close()\n",
        "\n",
        "        if args.dataset_type == 'med_vqa':\n",
        "            if args.dataset_cat == 'cat1':\n",
        "                convert_arr = ['cta - ct angiography', 'no', 'us - ultrasound', 'xr - plain film', 'noncontrast', 'yes', 't2', 'ct w/contrast (iv)', 'mr - flair', 'mammograph', 'ct with iv contrast',\n",
        "                            'gi and iv', 't1', 'mr - t2 weighted', 'mr - t1w w/gadolinium', 'contrast', 'iv', 'an - angiogram', 'mra - mr angiography/venography', 'nm - nuclear medicine', 'mr - dwi diffusion weighted',\n",
        "                            'ct - gi & iv contrast', 'ct noncontrast', 'mr - other pulse seq.', 'ct with gi and iv contrast', 'flair', 'mr - t1w w/gd (fat suppressed)', 'ugi - upper gi', 'mr - adc map (app diff coeff)',\n",
        "                            'bas - barium swallow', 'pet - positron emission', 'mr - pdw proton density', 'mr - t1w - noncontrast', 'be - barium enema', 'us-d - doppler ultrasound', 'mr - stir', 'mr - flair w/gd',\n",
        "                            'ct with gi contrast', 'venogram', 'mr t2* gradient,gre,mpgr,swan,swi', 'mr - fiesta', 'ct - myelogram', 'gi', 'sbft - small bowel', 'pet-ct fusion']\n",
        "            elif args.dataset_cat == 'cat2':\n",
        "                convert_arr = ['axial', 'longitudinal', 'coronal', 'lateral', 'ap', 'sagittal', 'mammo - mlo', 'pa', 'mammo - cc', 'transverse', 'mammo - mag cc', 'frontal', 'oblique', '3d reconstruction', 'decubitus', 'mammo - xcc']\n",
        "            else:\n",
        "                convert_arr = ['lung, mediastinum, pleura', 'skull and contents', 'genitourinary', 'spine and contents', 'musculoskeletal', 'heart and great vessels', 'vascular and lymphatic', 'gastrointestinal', 'face, sinuses, and neck', 'breast']\n",
        "        elif args.dataset_type == 'c80':\n",
        "            convert_arr = ['no', 'calot triangle dissection', 'yes', '1', '2', 'gallbladder dissection',\n",
        "                            'clipping cutting', 'gallbladder retraction', '0', 'cleaning coagulation',\n",
        "                            'gallbladder packaging', 'preparation', '3']\n",
        "        elif args.dataset_type == 'm18':\n",
        "            convert_arr = ['kidney', 'Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation',\n",
        "                            'Tool_Manipulation', 'Cutting', 'Cauterization', 'Suction',\n",
        "                            'Looping', 'Suturing', 'Clipping', 'Staple', 'Ultrasound_Sensing',\n",
        "                            'left-top', 'right-top', 'left-bottom', 'right-bottom']\n",
        "\n",
        "        df = pd.DataFrame(columns=[\"Img\", \"Ground Truth\", \"Prediction\"])\n",
        "        for i in range(len(label_true)):\n",
        "            df = df.append({'Img': file_names[i], 'Ground Truth': convert_arr[label_true[i]], 'Prediction': convert_arr[label_pred[i]]}, ignore_index=True)\n",
        "\n",
        "        df.to_csv(args.checkpoint_dir + args.checkpoint_dir.split('/')[1] + '_' + args.checkpoint_dir.split('/')[2] + '_eval.csv')\n",
        "\n",
        "    return (acc, c_acc, precision, recall, fscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSmyDMWNZg4a"
      },
      "outputs": [],
      "source": [
        "# training function for our CL algorithm\n",
        "def train_d3_d4(args, train_dataloader, model, criterion, optimizer, epoch, tokenizer, device):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    label_true = None\n",
        "    label_pred = None\n",
        "    label_score = None\n",
        "\n",
        "\n",
        "    for i, (_, visual_features, q, labels, t5_loss) in enumerate(train_dataloader,0):\n",
        "\n",
        "        label_number = labels.numpy()[0]\n",
        "\n",
        "        # prepare questions\n",
        "        questions = []\n",
        "        for question in q: questions.append(question)\n",
        "        inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
        "\n",
        "        # t5 loss\n",
        "        t5_loss_list = []\n",
        "        for j in range(len(t5_loss)):\n",
        "          #tmp = str2list(t5_loss[j])\n",
        "          tmp = t5_loss[j][:22]\n",
        "          t5_loss_list.append(tmp)\n",
        "        check = np.reciprocal(t5_loss_list)\n",
        "        t5_loss_tensor = torch.tensor(check)\n",
        "        t5_loss_tensor = t5_loss_tensor.to(device)\n",
        "\n",
        "        # GPU / CPU\n",
        "        visual_features = visual_features.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs, visual_features)\n",
        "\n",
        "        soft_target_17 = model_17(inputs, visual_features)\n",
        "        soft_target_18 = model_18(inputs, visual_features)\n",
        "\n",
        "        loss1 = criterion(outputs, labels)\n",
        "\n",
        "        outputs_S = F.softmax(outputs[:,:out_features]/T,dim=1)\n",
        "        outputs_T_17 = F.softmax(soft_target_17[:,:out_features]/T,dim=1)\n",
        "        outputs_T_18 = F.softmax(soft_target_18[:,:out_features]/T,dim=1)\n",
        "        outputs_t5_loss = F.softmax(t5_loss_tensor[:,:out_features]/T,dim=1)\n",
        "\n",
        "        loss2_17 = outputs_T_17.mul(-1*torch.log(outputs_S))\n",
        "        loss2_17 = loss2_17.sum(1)\n",
        "        loss2_17 = loss2_17.mean()*T*T\n",
        "\n",
        "        loss2_18 = outputs_T_18.mul(-1*torch.log(outputs_S))\n",
        "        loss2_18 = loss2_18.sum(1)\n",
        "        loss2_18 = loss2_18.mean()*T*T\n",
        "\n",
        "        loss3 = outputs_t5_loss.mul(-1*torch.log(outputs_S))\n",
        "        loss3 = loss3.sum(1)\n",
        "        loss3 = loss3.mean()*T*T\n",
        "\n",
        "        #loss = loss1 * 0.8 + loss2 * 0.123 + loss3 * 0.077\n",
        "        loss = loss1 * acc_weight.at[label_number,'weight_true_label'] + loss2_17 * (acc_weight.at[label_number,'weight_soft']*0.5) + loss2_18 * (acc_weight.at[label_number,'weight_soft']*0.5) + loss3 * acc_weight.at[label_number,'weight_llm']\n",
        "\n",
        "        # outputs_S = F.softmax(outputs[:,:out_features]/T,dim=1)\n",
        "        # outputs_T = F.softmax(soft_target[:,:out_features]/T,dim=1)\n",
        "        # outputs_t5_loss = F.softmax(t5_loss_tensor[:,:out_features]/T,dim=1)\n",
        "\n",
        "        # loss2 = outputs_T.mul(-1*torch.log(outputs_S))\n",
        "        # loss2 = loss2.sum(1)\n",
        "        # loss2 = loss2.mean()*T*T\n",
        "\n",
        "        # loss3 = outputs_t5_loss.mul(-1*torch.log(outputs_S))\n",
        "        # loss3 = loss3.sum(1)\n",
        "        # loss3 = loss3.mean()*T*T\n",
        "\n",
        "        # #loss = loss1 * 0.8 + loss2 * 0.123 + loss3 * 0.077\n",
        "        # loss = loss1 * acc_weight.at[label_number,'weight_true_label'] + loss2 * acc_weight.at[label_number,'weight_soft'] + loss3 * acc_weight.at[label_number,'weight_llm']\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)\n",
        "        label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n",
        "        label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n",
        "        label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n",
        "\n",
        "    # loss and acc\n",
        "    acc, c_acc = calc_acc(label_true, label_pred), calc_classwise_acc(label_true, label_pred)\n",
        "    precision, recall, fscore = calc_precision_recall_fscore(label_true, label_pred)\n",
        "    print('Train: epoch: %d loss: %.6f | Acc: %.6f | Precision: %.6f | Recall: %.6f | FScore: %.6f' %(epoch, total_loss, acc, precision, recall, fscore))\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO22hFlWZs7g"
      },
      "outputs": [],
      "source": [
        "def validate_d3_d4(args, val_loader, model, criterion, epoch, tokenizer, device, save_output = False):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    label_true = None\n",
        "    label_pred = None\n",
        "    label_score = None\n",
        "    file_names = list()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (file_name, visual_features, q, labels, _) in enumerate(val_loader,0):\n",
        "            # prepare questions\n",
        "            questions = []\n",
        "            for question in q: questions.append(question)\n",
        "            inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
        "\n",
        "            # GPU / CPU\n",
        "            visual_features = visual_features.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs, visual_features)\n",
        "\n",
        "\n",
        "            loss = criterion(outputs,labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)\n",
        "\n",
        "\n",
        "            label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n",
        "            label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n",
        "            label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n",
        "            for f in file_name: file_names.append(f)\n",
        "\n",
        "    acc = calc_acc(label_true, label_pred)\n",
        "    c_acc = 0.0\n",
        "    # c_acc = calc_classwise_acc(label_true, label_pred)\n",
        "    precision, recall, fscore = calc_precision_recall_fscore(label_true, label_pred)\n",
        "\n",
        "    print('Test: epoch: %d loss: %.6f | Acc: %.6f | Precision: %.6f | Recall: %.6f | FScore: %.6f' %(epoch, total_loss, acc, precision, recall, fscore))\n",
        "\n",
        "    if save_output:\n",
        "        '''\n",
        "            Saving predictions\n",
        "        '''\n",
        "        if os.path.exists(args.checkpoint_dir + 'text_files') == False:\n",
        "            os.mkdir(args.checkpoint_dir + 'text_files' )\n",
        "        file1 = open(args.checkpoint_dir + 'text_files/labels.txt', 'w')\n",
        "        file1.write(str(label_true))\n",
        "        file1.close()\n",
        "\n",
        "        file1 = open(args.checkpoint_dir + 'text_files/predictions.txt', 'w')\n",
        "        file1.write(str(label_pred))\n",
        "        file1.close()\n",
        "\n",
        "        if args.dataset_type == 'med_vqa':\n",
        "            if args.dataset_cat == 'cat1':\n",
        "                convert_arr = ['cta - ct angiography', 'no', 'us - ultrasound', 'xr - plain film', 'noncontrast', 'yes', 't2', 'ct w/contrast (iv)', 'mr - flair', 'mammograph', 'ct with iv contrast',\n",
        "                            'gi and iv', 't1', 'mr - t2 weighted', 'mr - t1w w/gadolinium', 'contrast', 'iv', 'an - angiogram', 'mra - mr angiography/venography', 'nm - nuclear medicine', 'mr - dwi diffusion weighted',\n",
        "                            'ct - gi & iv contrast', 'ct noncontrast', 'mr - other pulse seq.', 'ct with gi and iv contrast', 'flair', 'mr - t1w w/gd (fat suppressed)', 'ugi - upper gi', 'mr - adc map (app diff coeff)',\n",
        "                            'bas - barium swallow', 'pet - positron emission', 'mr - pdw proton density', 'mr - t1w - noncontrast', 'be - barium enema', 'us-d - doppler ultrasound', 'mr - stir', 'mr - flair w/gd',\n",
        "                            'ct with gi contrast', 'venogram', 'mr t2* gradient,gre,mpgr,swan,swi', 'mr - fiesta', 'ct - myelogram', 'gi', 'sbft - small bowel', 'pet-ct fusion']\n",
        "            elif args.dataset_cat == 'cat2':\n",
        "                convert_arr = ['axial', 'longitudinal', 'coronal', 'lateral', 'ap', 'sagittal', 'mammo - mlo', 'pa', 'mammo - cc', 'transverse', 'mammo - mag cc', 'frontal', 'oblique', '3d reconstruction', 'decubitus', 'mammo - xcc']\n",
        "            else:\n",
        "                convert_arr = ['lung, mediastinum, pleura', 'skull and contents', 'genitourinary', 'spine and contents', 'musculoskeletal', 'heart and great vessels', 'vascular and lymphatic', 'gastrointestinal', 'face, sinuses, and neck', 'breast']\n",
        "        elif args.dataset_type == 'c80':\n",
        "            convert_arr = ['no', 'calot triangle dissection', 'yes', '1', '2', 'gallbladder dissection',\n",
        "                            'clipping cutting', 'gallbladder retraction', '0', 'cleaning coagulation',\n",
        "                            'gallbladder packaging', 'preparation', '3']\n",
        "        elif args.dataset_type == 'm18':\n",
        "            convert_arr = ['kidney', 'Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation',\n",
        "                            'Tool_Manipulation', 'Cutting', 'Cauterization', 'Suction',\n",
        "                            'Looping', 'Suturing', 'Clipping', 'Staple', 'Ultrasound_Sensing',\n",
        "                            'left-top', 'right-top', 'left-bottom', 'right-bottom']\n",
        "\n",
        "        df = pd.DataFrame(columns=[\"Img\", \"Ground Truth\", \"Prediction\"])\n",
        "        for i in range(len(label_true)):\n",
        "            df = df.append({'Img': file_names[i], 'Ground Truth': convert_arr[label_true[i]], 'Prediction': convert_arr[label_pred[i]]}, ignore_index=True)\n",
        "\n",
        "        df.to_csv(args.checkpoint_dir + args.checkpoint_dir.split('/')[1] + '_' + args.checkpoint_dir.split('/')[2] + '_eval.csv')\n",
        "\n",
        "    return (acc, c_acc, precision, recall, fscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2U0-bmYrZwAy"
      },
      "outputs": [],
      "source": [
        "parser = argparse.ArgumentParser(description='VisualQuestionAnswerClassification')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFwtYN9BZ-kq"
      },
      "outputs": [],
      "source": [
        "parser.add_argument('--emb_dim',     type=int,  default=300, help='dimension of word embeddings.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfkYxKvtZ-Sp"
      },
      "outputs": [],
      "source": [
        "parser.add_argument('--n_heads',     type=int,  default=8,  help='Multi-head attention.')\n",
        "parser.add_argument('--dropout',     type=float, default=0.1, help='dropout')\n",
        "parser.add_argument('--encoder_layers',  type=int,  default=6,  help='the number of layers of encoder in Transformer.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FAcRqTwaaO3"
      },
      "outputs": [],
      "source": [
        "# Training parameters\n",
        "parser.add_argument('--epochs',       type=int,   default=80,     help='number of epochs to train for (if early stopping is not triggered).') #80, 26\n",
        "parser.add_argument('--batch_size',     type=int,   default=64,      help='batch_size')\n",
        "parser.add_argument('--workers',      type=int,   default=1,     help='for data-loading; right now, only 1 works with h5pys.')\n",
        "parser.add_argument('--print_freq',     type=int,   default=100,     help='print training/validation stats every __ batches.')\n",
        "\n",
        "# existing checkpoint\n",
        "parser.add_argument('--checkpoint',     default=None,             help='path to checkpoint, None if none.')\n",
        "\n",
        "parser.add_argument('--lr', type=float,  default=0.00001, help='0.000005, 0.00001, 0.000005')\n",
        "parser.add_argument('--checkpoint_dir',   default= '/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18/result/',    help='med_vqa_c$version$/m18/c80//m18_vid$temporal_size$/c80_vid$temporal_size$') #clf_v1_2_1x1/med_vqa_c3\n",
        "parser.add_argument('--dataset_type',    default= 'm18',         help='med_vqa/m18/c80/m18_vid/c80_vid')\n",
        "parser.add_argument('--dataset_cat',    default= 'None',         help='cat1/cat2/cat3')\n",
        "parser.add_argument('--transformer_ver',  default= 'vbrm',         help='vb/vbrm')\n",
        "parser.add_argument('--tokenizer_ver',   default= 'v2',          help='v2/v3')\n",
        "parser.add_argument('--patch_size',     default= 5,           help='1/2/3/4/5')\n",
        "parser.add_argument('--temporal_size',   default= 3,           help='1/2/3/4/5')\n",
        "parser.add_argument('--question_len',    default= 25,          help='25')\n",
        "parser.add_argument('--num_class',     default= 2,           help='25')\n",
        "parser.add_argument('--validate',      default=False,          help='When only validation required False/True')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9GEDvXfbS4a"
      },
      "outputs": [],
      "source": [
        "parser.add_argument('-f')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "injs_EEEbXEy"
      },
      "outputs": [],
      "source": [
        "args = parser.parse_args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jH_3QP_9bcE0"
      },
      "outputs": [],
      "source": [
        "# load checkpoint, these parameters can't be modified\n",
        "final_args = {\"emb_dim\": 300, \"n_heads\": 8, \"dropout\": 0.1, \"encoder_layers\": 6}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYYWg4abbf8U"
      },
      "outputs": [],
      "source": [
        "seed_everything()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baxNHnoabiN2"
      },
      "outputs": [],
      "source": [
        "# GPU or CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n",
        "cudnn.benchmark = True  # set to true only if inputs to model are fixed size; otherwise lot of computational overhead\n",
        "print('device =', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHTkp2NSbma-"
      },
      "outputs": [],
      "source": [
        "# best model initialize\n",
        "start_epoch = 1\n",
        "best_epoch = [0]\n",
        "best_results = [0.0]\n",
        "epochs_since_improvement = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4Zfn7fHboTq"
      },
      "outputs": [],
      "source": [
        "# tokenizer\n",
        "tokenizer = None\n",
        "tokenizer = BertTokenizer.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjC-eg_YdL7E"
      },
      "outputs": [],
      "source": [
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7i8942GdZDy"
      },
      "outputs": [],
      "source": [
        "args.num_class = 18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-3t1VlVdcOL"
      },
      "outputs": [],
      "source": [
        "#if args.transformer_ver == 'vb':\n",
        "model = VisualBertClassification(vocab_size=len(tokenizer), layers=6, n_heads=8, num_class = args.num_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLutJbeodgdC"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reTeLejRdj24"
      },
      "outputs": [],
      "source": [
        "# 将一个表示浮点数列表的字符串转换为实际的浮点数列表\n",
        "def str2list(target_str):\n",
        "  res=target_str.strip('[')\n",
        "  res=res.strip(']')\n",
        "  res=res.split(',')\n",
        "\n",
        "  for i in range(len(res)):\n",
        "    res[i] = res[i].strip() # 去掉空格\n",
        "\n",
        "  new_list = [float(x) for x in res]\n",
        "  return new_list[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWMuLIWDdoE_"
      },
      "source": [
        "Imbalance Issue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ga6aYE6d1gh"
      },
      "outputs": [],
      "source": [
        "# Since the three dataset is already fixed, we pre-store the label distribution in a CSV file to save the time loading all the data\n",
        "# Load all the data will be a VERY time-consuming in Colab\n",
        "import math\n",
        "\n",
        "frequency_all = pd.read_csv(\"frequency_all.csv\")\n",
        "max_17_18_daisi = frequency_all['17+18+daisi'].max()\n",
        "min_17_18_daisi = frequency_all['17+18+daisi'].min()\n",
        "IR_17_18_daisi = max_17_18_daisi / min_17_18_daisi\n",
        "ln_IR_17_18_daisi = math.log(IR_17_18_daisi,N_Balance)\n",
        "print(ln_IR_17_18_daisi)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im_lwdSKtlZu"
      },
      "source": [
        "Load DAISI and CL model trained on 17,18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uJsNsartprm"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "class DaisiVQADataset(Dataset):\n",
        "    def __init__(self, csv_file, data_type, patch_size=5):\n",
        "        self.patch_size = patch_size\n",
        "        tmp = pd.read_csv(csv_file)\n",
        "        self.data_frame = tmp[tmp['type']==data_type]\n",
        "        unique_files = len(self.data_frame['path'].unique())\n",
        "        total_questions = len(self.data_frame)\n",
        "        print(f\"Total files: {unique_files} | Total questions: {total_questions}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data_frame.iloc[idx]\n",
        "        q = sample['q']\n",
        "        labels = torch.tensor(sample['labels'])\n",
        "        file_name = str(sample['path'])\n",
        "\n",
        "        visual_feature_loc = '/' + os.path.join('content/drive/MyDrive/Colab Notebooks/research/multi-modality/daisi_vqa_final/data/',file_name,'vqa/img_features',(str(self.patch_size)+'x'+str(self.patch_size)),file_name+'.hdf5')\n",
        "        frame_data = h5py.File(visual_feature_loc, 'r')\n",
        "        visual_features = torch.from_numpy(frame_data['visual_features'][:])\n",
        "\n",
        "        t5_loss = torch.tensor(eval(sample['t5_loss']))\n",
        "\n",
        "        return file_name, visual_features, q, labels, t5_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTZDIvzhuqCO"
      },
      "outputs": [],
      "source": [
        "train_dataset_daisi = DaisiVQADataset('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/daisi_vqa_final/daisi_data.csv','train',patch_size=5)\n",
        "train_dataloader = DataLoader(dataset=train_dataset_daisi, batch_size=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmgWwQviwwY-"
      },
      "outputs": [],
      "source": [
        "val_dataset_17 = EndoVis17VQAClassification([8],'/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis17/seq_',\n",
        "                        '/vqa/*.txt', patch_size = 5)\n",
        "val_dataloader_17 = DataLoader(dataset=val_dataset_17, batch_size= 64, shuffle=False)\n",
        "\n",
        "val_dataset_18 = EndoVis18VQAClassification([1,5,16],'/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18/seq_',\n",
        "                          '/vqa/Classification_t5_loss/*.txt', patch_size = 5)\n",
        "val_dataloader_18 = DataLoader(dataset=val_dataset_18, batch_size= 64, shuffle=False)\n",
        "\n",
        "val_dataset_daisi = DaisiVQADataset('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/daisi_vqa_final/daisi_data.csv',\n",
        "                                        'val',patch_size=5)\n",
        "val_dataloader_daisi = DataLoader(dataset=val_dataset_daisi, batch_size=1, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8Cj0CStzgyV"
      },
      "outputs": [],
      "source": [
        "# 17 model\n",
        "checkpoint_17 = torch.load('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis17/Pretrain_t1.pth.tar')\n",
        "model_17 = checkpoint_17['model']\n",
        "\n",
        "# 18 model\n",
        "checkpoint_18 = torch.load('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis17/Pretrain_t2.pth.tar')\n",
        "model_18 = checkpoint_18['model']\n",
        "\n",
        "# daisi model\n",
        "checkpoint = torch.load('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis17/Pretrain_t2.pth.tar')\n",
        "model = checkpoint['model']\n",
        "\n",
        "optimizer = checkpoint['optimizer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tw__VM-pz3Fd"
      },
      "outputs": [],
      "source": [
        "#change the last FC layer for new model (add the node for new classes)\n",
        "num_new_class = 2\n",
        "\n",
        "def kaiming_normal_init(m):\n",
        "\tif isinstance(m, nn.Conv2d):\n",
        "\t\tnn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "\telif isinstance(m, nn.Linear):\n",
        "\t\tnn.init.kaiming_normal_(m.weight, nonlinearity='sigmoid')\n",
        "\n",
        "# Old number of input/output channel of the last FC layer in old model\n",
        "in_features = model.classifier.in_features\n",
        "out_features = model.classifier.out_features\n",
        "\n",
        "# Old weight/bias of the last FC layer\n",
        "weight = model.classifier.weight.data\n",
        "bias = model.classifier.bias.data\n",
        "\n",
        "# New number of output channel of the last FC layer in new model\n",
        "new_out_features = num_new_class + out_features\n",
        "\n",
        "# Creat a new FC layer and initial it's weight/bias\n",
        "new_fc = nn.Linear(in_features, new_out_features)\n",
        "kaiming_normal_init(new_fc.weight)\n",
        "new_fc.weight.data[:out_features] = weight\n",
        "new_fc.bias.data[:out_features] = bias\n",
        "\n",
        "# Replace the old FC layer\n",
        "model.classifier = new_fc\n",
        "model_17.classifier = new_fc\n",
        "model_18.classifier = new_fc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwHMcfef0Rb1"
      },
      "outputs": [],
      "source": [
        "# Move to GPU, if available\n",
        "model = model.to(device)\n",
        "\n",
        "model_17 = model_17.to(device)\n",
        "model_18 = model_18.to(device)\n",
        "\n",
        "print(final_args)\n",
        "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
        "print('model params: ', pytorch_total_params)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRxkR64R0bk1"
      },
      "outputs": [],
      "source": [
        "args.checkpoint_dir = '/content/drive/MyDrive/Colab Notebooks/research/multi-modality/daisi_vqa_final/result/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IkmDXMJ0fgs"
      },
      "outputs": [],
      "source": [
        "# best model initialize\n",
        "start_epoch = 1\n",
        "best_epoch = [0]\n",
        "best_results = [0.0]\n",
        "epochs_since_improvement = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWkeNNee0hSd"
      },
      "outputs": [],
      "source": [
        "out_features = model.classifier.out_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwkF9q7Mioho"
      },
      "source": [
        "soft target 和大模型准确率"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eisitO6HivDD"
      },
      "outputs": [],
      "source": [
        "# label = []\n",
        "# label_soft_list = [] #软标签（旧模型所得）\n",
        "\n",
        "# for i, (_, visual_features, q, labels, t5_loss) in enumerate(train_dataloader,0):\n",
        "\n",
        "#     label_number = labels.numpy()[0]\n",
        "#     label += labels.tolist()\n",
        "\n",
        "#     # prepare questions\n",
        "#     questions = []\n",
        "#     for question in q: questions.append(question)\n",
        "#     inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
        "\n",
        "#     # GPU / CPU\n",
        "#     visual_features = visual_features.to(device)\n",
        "#     labels = labels.to(device)\n",
        "\n",
        "#     soft_target = model_18(inputs, visual_features)\n",
        "#     output_class_ranks = torch.argsort(soft_target, dim=-1, descending=True)\n",
        "\n",
        "#     label_soft = []\n",
        "#     for j in range(len(output_class_ranks)):\n",
        "#         label_soft.append(int(output_class_ranks[j][0]))\n",
        "#     label_soft_list += label_soft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmNf9X1PyjX_"
      },
      "outputs": [],
      "source": [
        "# from pandas.core.frame import DataFrame\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# import math\n",
        "\n",
        "# c={\"label\" : label, \"label_soft_list\" : label_soft_list}\n",
        "# data=DataFrame(c)\n",
        "# acc_soft = []\n",
        "# for i in range(22):\n",
        "#     label_part = []\n",
        "#     label_soft_part = []\n",
        "#     for j in range(len(data)):\n",
        "#         if data.at[j,'label'] == i:\n",
        "#             label_part.append(data.at[j,'label'])\n",
        "#             label_soft_part.append(data.at[j,'label_soft_list'])\n",
        "#     acc_soft.append(accuracy_score(label_part, label_soft_part))\n",
        "# acc_soft = [0 if math.isnan(x) else x for x in acc_soft]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eu5lvRiti29y"
      },
      "outputs": [],
      "source": [
        "# label = []\n",
        "# label_llm_list = []\n",
        "\n",
        "# for i, (_, visual_features, q, labels, t5_loss) in enumerate(train_dataloader,0):\n",
        "#   label += labels.tolist()\n",
        "\n",
        "#   t5_loss_list = []\n",
        "#   for j in range(len(t5_loss)):\n",
        "#     #tmp = str2list(t5_loss[j])\n",
        "#     tmp = t5_loss[j][:22]\n",
        "#     t5_loss_list.append(tmp)\n",
        "\n",
        "#   check = np.reciprocal(t5_loss_list)\n",
        "#   t5_loss_tensor = torch.tensor(check)\n",
        "#   output_class_ranks = torch.argsort(t5_loss_tensor, dim=-1, descending=True)\n",
        "\n",
        "#   label_llm = []\n",
        "#   for j in range(len(output_class_ranks)):\n",
        "#     label_llm.append(int(output_class_ranks[j][0]))\n",
        "\n",
        "#   label_llm_list += label_llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOEeYnXAzce3"
      },
      "outputs": [],
      "source": [
        "# c={\"label\" : label, \"label_llm_list\" : label_llm_list}\n",
        "# data=DataFrame(c)\n",
        "\n",
        "# acc_llm = []\n",
        "\n",
        "# for i in range(22):\n",
        "#   label_part = []\n",
        "#   label_llm_part = []\n",
        "\n",
        "#   for j in range(len(data)):\n",
        "#     if data.at[j,'label'] == i:\n",
        "#       label_part.append(data.at[j,'label'])\n",
        "#       label_llm_part.append(data.at[j,'label_llm_list'])\n",
        "\n",
        "#   if len(label_part) == 0:\n",
        "#     acc_llm.append(0)\n",
        "#   else:\n",
        "#     acc_llm.append(accuracy_score(label_part, label_llm_part))\n",
        "\n",
        "# acc_llm = [0 if math.isnan(x) else x for x in acc_llm]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owQO074p8z6z"
      },
      "outputs": [],
      "source": [
        "# acc_soft"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmDsgP4Sy2j5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHKzeLy-85Cb"
      },
      "outputs": [],
      "source": [
        "# acc_llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6fgASYVi9Pb"
      },
      "outputs": [],
      "source": [
        "#无删减y/n\n",
        "acc_soft=[1.0,1.0,0,0,0,0,0.019801980198019802,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "acc_llm=[0,0,0,0,0,0,0.6831683168316832,0,0,0,0,0,0.3076923076923077,0,0,0,0,0,0.5683453237410072,0.5691056910569106,0,0]\n",
        "\n",
        "from pandas.core.frame import DataFrame\n",
        "from sklearn.metrics import accuracy_score\n",
        "import math\n",
        "\n",
        "c={\"acc_soft\" : acc_soft, \"acc_llm\" : acc_llm}\n",
        "\n",
        "weight_data_17_18_daisi=DataFrame(c)\n",
        "\n",
        "\n",
        "for i in range(len(weight_data_17_18_daisi)):\n",
        "  if weight_data_17_18_daisi.at[i,'acc_soft'] + weight_data_17_18_daisi.at[i,'acc_llm'] == 0:\n",
        "    weight_data_17_18_daisi.at[i,'DS_soft'] = 0.5*(1 - hard_label_weight)\n",
        "    weight_data_17_18_daisi.at[i,'DS_llm'] = 0.5*(1 - hard_label_weight)\n",
        "  else:\n",
        "    weight_data_17_18_daisi.at[i,'DS_soft'] = (1-hard_label_weight) * weight_data_17_18_daisi.at[i,'acc_soft'] / (weight_data_17_18_daisi.at[i,'acc_soft'] + weight_data_17_18_daisi.at[i,'acc_llm'])\n",
        "    weight_data_17_18_daisi.at[i,'DS_llm'] = (1-hard_label_weight) * weight_data_17_18_daisi.at[i,'acc_llm'] / (weight_data_17_18_daisi.at[i,'acc_soft'] + weight_data_17_18_daisi.at[i,'acc_llm'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzZvYsmzjEkN"
      },
      "outputs": [],
      "source": [
        "#weight processing\n",
        "weight_data_17_18_daisi['DI_soft']=(1-hard_label_weight) * (1 / (1 + ln_IR_17_18_daisi))\n",
        "weight_data_17_18_daisi['DI_llm'] = (1-hard_label_weight) * ((ln_IR_17_18_daisi) / (1 + ln_IR_17_18_daisi))\n",
        "weight_data_17_18_daisi['weight_true_label']=hard_label_weight\n",
        "weight_data_17_18_daisi['weight_soft'] = DS_weight * weight_data_17_18_daisi['DS_soft'] + DI_weight * weight_data_17_18_daisi['DI_soft']\n",
        "weight_data_17_18_daisi['weight_llm'] = DS_weight * weight_data_17_18_daisi['DS_llm'] + DI_weight * weight_data_17_18_daisi['DI_llm']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4q8aJFUljEdj"
      },
      "outputs": [],
      "source": [
        "acc_weight = weight_data_17_18_daisi[['weight_true_label','weight_soft','weight_llm']]\n",
        "acc_weight.weight_data_17_18_daisi = ['weight_true_label','weight_soft','weight_llm']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rZA1ZVCxT1H"
      },
      "outputs": [],
      "source": [
        "len(weight_data_17_18_daisi)\n",
        "acc_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deeoCiC33DWm"
      },
      "outputs": [],
      "source": [
        "# # validation\n",
        "# #test 17\n",
        "# test_acc_17, test_c_acc, test_precision, test_recall, test_fscore = validate_17_18(args,val_loader=val_dataloader_17, model = model_18, criterion=criterion, epoch=0, tokenizer = tokenizer, device = device)\n",
        "\n",
        "# #test 18\n",
        "# test_acc_18, test_c_acc, test_precision, test_recall, test_fscore = validate_d3_d4(args,val_loader=val_dataloader_18, model = model_18, criterion=criterion, epoch=0, tokenizer = tokenizer, device = device)\n",
        "\n",
        "# # #test daisi\n",
        "# # test_acc_daisi, test_c_acc, test_precision, test_recall, test_fscore = validate_non18(args,val_loader=val_dataloader_daisi, model = model, criterion=criterion, epoch=epoch, tokenizer = tokenizer, device = device)\n",
        "\n",
        "# # test_acc, test_c_acc, test_precision, test_recall, test_fscore = validate_non17(args, val_loader=val_dataloader_d4, model = model, criterion=criterion, epoch=epoch, tokenizer = tokenizer, device = device)\n",
        "\n",
        "# # test_acc_d4=test_acc\n",
        "\n",
        "# # av_acc = (test_acc_d4+test_acc_17+test_acc_18+test_acc_daisi)/4\n",
        "# # print('epoch: %d | Average acc: %.6f' %(epoch, av_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIKNk_2xjEM0"
      },
      "outputs": [],
      "source": [
        "for epoch in range(start_epoch, epoch_num): # train only a few epoch to reduce training time\n",
        "\n",
        "  if epochs_since_improvement > 0 and epochs_since_improvement % 5 == 0:\n",
        "    adjust_learning_rate(optimizer, 0.8)\n",
        "\n",
        "  # train\n",
        "  train_acc = train_d3_d4(args, train_dataloader=train_dataloader, model = model, criterion=criterion, optimizer=optimizer, epoch=epoch, tokenizer = tokenizer, device = device)\n",
        "\n",
        "  # validation\n",
        "  #test 17\n",
        "  test_acc_17, test_c_acc, test_precision, test_recall, test_fscore = validate_17_18(args,val_loader=val_dataloader_17, model = model, criterion=criterion, epoch=epoch, tokenizer = tokenizer, device = device)\n",
        "\n",
        "  #test 18\n",
        "  test_acc_18, test_c_acc, test_precision, test_recall, test_fscore = validate_d3_d4(args,val_loader=val_dataloader_18, model = model, criterion=criterion, epoch=epoch, tokenizer = tokenizer, device = device)\n",
        "\n",
        "  #test daisi\n",
        "  test_acc_daisi, test_c_acc, test_precision, test_recall, test_fscore = validate_d3_d4(args,val_loader=val_dataloader_daisi, model = model, criterion=criterion, epoch=epoch, tokenizer = tokenizer, device = device)\n",
        "\n",
        "\n",
        "  av_acc = (test_acc_17+test_acc_18+test_acc_daisi)/3\n",
        "  print('epoch: %d | Average acc: %.6f' %(epoch, av_acc))\n",
        "\n",
        "  if av_acc >= best_results[0]:\n",
        "    epochs_since_improvement = 0\n",
        "\n",
        "    best_results[0] = av_acc\n",
        "    best_epoch[0] = epoch\n",
        "    # save_clf_checkpoint(args.checkpoint_dir, epoch, epochs_since_improvement, model, optimizer, best_results[0], final_args)\n",
        "\n",
        "  else:\n",
        "    epochs_since_improvement += 1\n",
        "\n",
        "  if train_acc >= 1.0: break\n",
        "\n",
        "  # if epoch==9:\n",
        "  #   save_clf_checkpoint(args.checkpoint_dir, epoch, epochs_since_improvement, model, optimizer, best_results[0], final_args)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
