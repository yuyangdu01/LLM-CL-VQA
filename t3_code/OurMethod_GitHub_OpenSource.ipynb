{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"jhHpP5zfPGKt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710087270423,"user_tz":-480,"elapsed":4654,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}},"outputId":"feee0bf3-68de-4138-d1a3-33f3cd74812c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"pPXnpT1R8Mo1","executionInfo":{"status":"ok","timestamp":1710087270423,"user_tz":-480,"elapsed":3,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["import os\n","os.chdir(\"/content/drive/MyDrive/Colab Notebooks/research/multi-modality/t3_code\")"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"4y4NNvR386GH","executionInfo":{"status":"ok","timestamp":1710087270976,"user_tz":-480,"elapsed":555,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["import argparse\n","import pandas as pd\n","from lib2to3.pytree import convert"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"kGA4rlBm86IY","executionInfo":{"status":"ok","timestamp":1710087272592,"user_tz":-480,"elapsed":1622,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["from torch import nn\n","from torch import optim\n","import torch.utils.data\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"RApt6Uhdg6s2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710087277317,"user_tz":-480,"elapsed":4728,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}},"outputId":"211b8be5-ada2-42bf-bd8c-a2b46ed5bb11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers==4.18.0 in /usr/local/lib/python3.10/dist-packages (4.18.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (2.31.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (0.1.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (0.12.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0) (2024.2.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.18.0) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.18.0) (1.3.2)\n"]}],"source":["pip install transformers==4.18.0"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"gNiBJ2ks86Ks","executionInfo":{"status":"ok","timestamp":1710087277854,"user_tz":-480,"elapsed":545,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["from transformers import BertTokenizer\n","from torch.utils.data  import DataLoader"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"lhr6LKkg9ezN","executionInfo":{"status":"ok","timestamp":1710087277854,"user_tz":-480,"elapsed":2,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["import sys\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/t3_code/Surgical_VQA')"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"y8RczgqT9e1i","executionInfo":{"status":"ok","timestamp":1710087279051,"user_tz":-480,"elapsed":1199,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["from utils import *\n","from dataloaders.dataloaderClassification import *\n","from models.VisualBertClassification import VisualBertClassification\n","from models.VisualBertResMLPClassification import VisualBertResMLPClassification"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"hdJKywmN9vL-","executionInfo":{"status":"ok","timestamp":1710087279052,"user_tz":-480,"elapsed":21,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"34DLKrvN9vOO","executionInfo":{"status":"ok","timestamp":1710087279052,"user_tz":-480,"elapsed":21,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["def seed_everything(seed=27):\n","    '''\n","    Set random seed for reproducible experiments\n","    Inputs: seed number\n","    '''\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","\n","def train(args, train_dataloader, model, criterion, optimizer, epoch, tokenizer, device):\n","\n","    model.train()\n","\n","    total_loss = 0.0\n","    label_true = None\n","    label_pred = None\n","    label_score = None\n","\n","\n","    for i, (_, visual_features, q, labels) in enumerate(train_dataloader,0):\n","\n","        # prepare questions\n","        questions = []\n","        for question in q: questions.append(question)\n","        inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n","\n","\n","        # GPU / CPU\n","        visual_features = visual_features.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(inputs, visual_features)\n","        loss = criterion(outputs, labels)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        total_loss += loss.item()\n","\n","        scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)\n","        label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n","        label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n","        label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n","\n","    # loss and acc\n","    acc, c_acc = calc_acc(label_true, label_pred), calc_classwise_acc(label_true, label_pred)\n","    precision, recall, fscore = calc_precision_recall_fscore(label_true, label_pred)\n","    print('Train: epoch: %d loss: %.6f | Acc: %.6f | Precision: %.6f | Recall: %.6f | FScore: %.6f' %(epoch, total_loss, acc, precision, recall, fscore))\n","    return acc\n","\n","\n","def validate(args, val_loader, model, criterion, epoch, tokenizer, device, save_output = False):\n","\n","    model.eval()\n","\n","    total_loss = 0.0\n","    label_true = None\n","    label_pred = None\n","    label_score = None\n","    file_names = list()\n","\n","    criterion = nn.CrossEntropyLoss()\n","\n","    with torch.no_grad():\n","        for i, (file_name, visual_features, q, labels) in enumerate(val_loader,0):\n","            # prepare questions\n","            questions = []\n","            for question in q: questions.append(question)\n","            inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n","\n","            # GPU / CPU\n","            visual_features = visual_features.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs, visual_features)\n","            loss = criterion(outputs,labels)\n","\n","            total_loss += loss.item()\n","\n","            scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)\n","            label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n","            label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n","            label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n","            for f in file_name: file_names.append(f)\n","\n","    acc = calc_acc(label_true, label_pred)\n","    c_acc = 0.0\n","    precision, recall, fscore = calc_precision_recall_fscore(label_true, label_pred)\n","\n","    if save_output:\n","        '''\n","            Saving predictions\n","        '''\n","        if os.path.exists(args.checkpoint_dir + 'text_files') == False:\n","            os.mkdir(args.checkpoint_dir + 'text_files' )\n","        file1 = open(args.checkpoint_dir + 'text_files/labels.txt', 'w')\n","        file1.write(str(label_true))\n","        file1.close()\n","\n","        file1 = open(args.checkpoint_dir + 'text_files/predictions.txt', 'w')\n","        file1.write(str(label_pred))\n","        file1.close()\n","\n","        if args.dataset_type == 'med_vqa':\n","            if args.dataset_cat == 'cat1':\n","                convert_arr = ['cta - ct angiography', 'no', 'us - ultrasound', 'xr - plain film', 'noncontrast', 'yes', 't2', 'ct w/contrast (iv)', 'mr - flair', 'mammograph', 'ct with iv contrast',\n","                            'gi and iv', 't1', 'mr - t2 weighted', 'mr - t1w w/gadolinium', 'contrast', 'iv', 'an - angiogram', 'mra - mr angiography/venography', 'nm - nuclear medicine', 'mr - dwi diffusion weighted',\n","                            'ct - gi & iv contrast', 'ct noncontrast', 'mr - other pulse seq.', 'ct with gi and iv contrast', 'flair', 'mr - t1w w/gd (fat suppressed)', 'ugi - upper gi', 'mr - adc map (app diff coeff)',\n","                            'bas - barium swallow', 'pet - positron emission', 'mr - pdw proton density', 'mr - t1w - noncontrast', 'be - barium enema', 'us-d - doppler ultrasound', 'mr - stir', 'mr - flair w/gd',\n","                            'ct with gi contrast', 'venogram', 'mr t2* gradient,gre,mpgr,swan,swi', 'mr - fiesta', 'ct - myelogram', 'gi', 'sbft - small bowel', 'pet-ct fusion']\n","            elif args.dataset_cat == 'cat2':\n","                convert_arr = ['axial', 'longitudinal', 'coronal', 'lateral', 'ap', 'sagittal', 'mammo - mlo', 'pa', 'mammo - cc', 'transverse', 'mammo - mag cc', 'frontal', 'oblique', '3d reconstruction', 'decubitus', 'mammo - xcc']\n","            else:\n","                convert_arr = ['lung, mediastinum, pleura', 'skull and contents', 'genitourinary', 'spine and contents', 'musculoskeletal', 'heart and great vessels', 'vascular and lymphatic', 'gastrointestinal', 'face, sinuses, and neck', 'breast']\n","        elif args.dataset_type == 'c80':\n","            convert_arr = ['no', 'calot triangle dissection', 'yes', '1', '2', 'gallbladder dissection',\n","                            'clipping cutting', 'gallbladder retraction', '0', 'cleaning coagulation',\n","                            'gallbladder packaging', 'preparation', '3']\n","        elif args.dataset_type == 'm18':\n","            convert_arr = ['kidney', 'Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation',\n","                            'Tool_Manipulation', 'Cutting', 'Cauterization', 'Suction',\n","                            'Looping', 'Suturing', 'Clipping', 'Staple', 'Ultrasound_Sensing',\n","                            'left-top', 'right-top', 'left-bottom', 'right-bottom']\n","\n","        df = pd.DataFrame(columns=[\"Img\", \"Ground Truth\", \"Prediction\"])\n","        for i in range(len(label_true)):\n","            df = df.append({'Img': file_names[i], 'Ground Truth': convert_arr[label_true[i]], 'Prediction': convert_arr[label_pred[i]]}, ignore_index=True)\n","\n","        df.to_csv(args.checkpoint_dir + args.checkpoint_dir.split('/')[1] + '_' + args.checkpoint_dir.split('/')[2] + '_eval.csv')\n","\n","    return (acc, c_acc, precision, recall, fscore)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Oy6LTj2Chx6y","executionInfo":{"status":"ok","timestamp":1710087279052,"user_tz":-480,"elapsed":20,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["def validate_18(args, val_loader, model, criterion, epoch, tokenizer, device, save_output = False):\n","\n","    model.eval()\n","\n","    total_loss = 0.0\n","    label_true = None\n","    label_pred = None\n","    label_score = None\n","    file_names = list()\n","\n","    criterion = nn.CrossEntropyLoss()\n","\n","    with torch.no_grad():\n","        for i, (file_name, visual_features, q, labels, _) in enumerate(val_loader,0):\n","            # prepare questions\n","            questions = []\n","            for question in q: questions.append(question)\n","            inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n","\n","            # GPU / CPU\n","            visual_features = visual_features.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs, visual_features)\n","            loss = criterion(outputs,labels)\n","\n","            total_loss += loss.item()\n","\n","            scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)\n","            label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n","            label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n","            label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n","            for f in file_name: file_names.append(f)\n","\n","    acc = calc_acc(label_true, label_pred)\n","    c_acc = 0.0\n","    # c_acc = calc_classwise_acc(label_true, label_pred)\n","    precision, recall, fscore = calc_precision_recall_fscore(label_true, label_pred)\n","\n","    if save_output:\n","        '''\n","            Saving predictions\n","        '''\n","        if os.path.exists(args.checkpoint_dir + 'text_files') == False:\n","            os.mkdir(args.checkpoint_dir + 'text_files' )\n","        file1 = open(args.checkpoint_dir + 'text_files/labels.txt', 'w')\n","        file1.write(str(label_true))\n","        file1.close()\n","\n","        file1 = open(args.checkpoint_dir + 'text_files/predictions.txt', 'w')\n","        file1.write(str(label_pred))\n","        file1.close()\n","\n","        if args.dataset_type == 'med_vqa':\n","            if args.dataset_cat == 'cat1':\n","                convert_arr = ['cta - ct angiography', 'no', 'us - ultrasound', 'xr - plain film', 'noncontrast', 'yes', 't2', 'ct w/contrast (iv)', 'mr - flair', 'mammograph', 'ct with iv contrast',\n","                            'gi and iv', 't1', 'mr - t2 weighted', 'mr - t1w w/gadolinium', 'contrast', 'iv', 'an - angiogram', 'mra - mr angiography/venography', 'nm - nuclear medicine', 'mr - dwi diffusion weighted',\n","                            'ct - gi & iv contrast', 'ct noncontrast', 'mr - other pulse seq.', 'ct with gi and iv contrast', 'flair', 'mr - t1w w/gd (fat suppressed)', 'ugi - upper gi', 'mr - adc map (app diff coeff)',\n","                            'bas - barium swallow', 'pet - positron emission', 'mr - pdw proton density', 'mr - t1w - noncontrast', 'be - barium enema', 'us-d - doppler ultrasound', 'mr - stir', 'mr - flair w/gd',\n","                            'ct with gi contrast', 'venogram', 'mr t2* gradient,gre,mpgr,swan,swi', 'mr - fiesta', 'ct - myelogram', 'gi', 'sbft - small bowel', 'pet-ct fusion']\n","            elif args.dataset_cat == 'cat2':\n","                convert_arr = ['axial', 'longitudinal', 'coronal', 'lateral', 'ap', 'sagittal', 'mammo - mlo', 'pa', 'mammo - cc', 'transverse', 'mammo - mag cc', 'frontal', 'oblique', '3d reconstruction', 'decubitus', 'mammo - xcc']\n","            else:\n","                convert_arr = ['lung, mediastinum, pleura', 'skull and contents', 'genitourinary', 'spine and contents', 'musculoskeletal', 'heart and great vessels', 'vascular and lymphatic', 'gastrointestinal', 'face, sinuses, and neck', 'breast']\n","        elif args.dataset_type == 'c80':\n","            convert_arr = ['no', 'calot triangle dissection', 'yes', '1', '2', 'gallbladder dissection',\n","                            'clipping cutting', 'gallbladder retraction', '0', 'cleaning coagulation',\n","                            'gallbladder packaging', 'preparation', '3']\n","        elif args.dataset_type == 'm18':\n","            convert_arr = ['kidney', 'Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation',\n","                            'Tool_Manipulation', 'Cutting', 'Cauterization', 'Suction',\n","                            'Looping', 'Suturing', 'Clipping', 'Staple', 'Ultrasound_Sensing',\n","                            'left-top', 'right-top', 'left-bottom', 'right-bottom']\n","\n","        df = pd.DataFrame(columns=[\"Img\", \"Ground Truth\", \"Prediction\"])\n","        for i in range(len(label_true)):\n","            df = df.append({'Img': file_names[i], 'Ground Truth': convert_arr[label_true[i]], 'Prediction': convert_arr[label_pred[i]]}, ignore_index=True)\n","\n","        df.to_csv(args.checkpoint_dir + args.checkpoint_dir.split('/')[1] + '_' + args.checkpoint_dir.split('/')[2] + '_eval.csv')\n","\n","    return (acc, c_acc, precision, recall, fscore)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"0fnLvtCt94V1","executionInfo":{"status":"ok","timestamp":1710087279053,"user_tz":-480,"elapsed":21,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["parser = argparse.ArgumentParser(description='VisualQuestionAnswerClassification')"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"3YtNNqp4Bmxd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710087279053,"user_tz":-480,"elapsed":21,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}},"outputId":"3391acfe-b49f-4cd7-840b-4acf49fecf92"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["_StoreAction(option_strings=['--emb_dim'], dest='emb_dim', nargs=None, const=None, default=300, type=<class 'int'>, choices=None, required=False, help='dimension of word embeddings.', metavar=None)"]},"metadata":{},"execution_count":13}],"source":["parser.add_argument('--emb_dim',        type=int,   default=300,                                help='dimension of word embeddings.')"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"wUKH05QrBm0V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710087279053,"user_tz":-480,"elapsed":18,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}},"outputId":"651c6057-31ca-432d-8e1a-adf01636cd62"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["_StoreAction(option_strings=['--encoder_layers'], dest='encoder_layers', nargs=None, const=None, default=6, type=<class 'int'>, choices=None, required=False, help='the number of layers of encoder in Transformer.', metavar=None)"]},"metadata":{},"execution_count":14}],"source":["parser.add_argument('--n_heads',        type=int,   default=8,                                  help='Multi-head attention.')\n","parser.add_argument('--dropout',        type=float, default=0.1,                                help='dropout')\n","parser.add_argument('--encoder_layers', type=int,   default=6,                                  help='the number of layers of encoder in Transformer.')"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"rUkuYH5dBm2j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710087279053,"user_tz":-480,"elapsed":15,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}},"outputId":"4031b1b3-0845-411f-810c-44b437ed9638"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["_StoreAction(option_strings=['--validate'], dest='validate', nargs=None, const=None, default=False, type=None, choices=None, required=False, help='When only validation required False/True', metavar=None)"]},"metadata":{},"execution_count":15}],"source":["    # Training parameters\n","    parser.add_argument('--epochs',         type=int,   default=80,                                 help='number of epochs to train for (if early stopping is not triggered).') #80, 26\n","    parser.add_argument('--batch_size',     type=int,   default=64,                                 help='batch_size')\n","    parser.add_argument('--workers',        type=int,   default=1,                                  help='for data-loading; right now, only 1 works with h5pys.')\n","    parser.add_argument('--print_freq',     type=int,   default=100,                                help='print training/validation stats every __ batches.')\n","\n","    # existing checkpoint\n","    parser.add_argument('--checkpoint',     default=None,                                           help='path to checkpoint, None if none.')\n","\n","    parser.add_argument('--lr',             type=float, default=0.00001,                            help='0.000005, 0.00001, 0.000005')\n","    parser.add_argument('--checkpoint_dir', default= '/content/drive/MyDrive/Colab Notebooks/research/multi-modality/svqa/checkpoints/18/',    help='med_vqa_c$version$/m18/c80//m18_vid$temporal_size$/c80_vid$temporal_size$') #clf_v1_2_1x1/med_vqa_c3\n","    parser.add_argument('--dataset_type',   default= 'm18',                                     help='med_vqa/m18/c80/m18_vid/c80_vid')\n","    parser.add_argument('--dataset_cat',    default= 'None',                                        help='cat1/cat2/cat3')\n","    parser.add_argument('--transformer_ver',default= 'vbrm',                                        help='vb/vbrm')\n","    parser.add_argument('--tokenizer_ver',  default= 'v2',                                          help='v2/v3')\n","    parser.add_argument('--patch_size',     default= 5,                                             help='1/2/3/4/5')\n","    parser.add_argument('--temporal_size',  default= 3,                                             help='1/2/3/4/5')\n","    parser.add_argument('--question_len',   default= 25,                                            help='25')\n","    parser.add_argument('--num_class',      default= 2,                                             help='25')\n","    parser.add_argument('--validate',       default=False,                                          help='When only validation required False/True')"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"927spLAMCdd-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710087279054,"user_tz":-480,"elapsed":14,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}},"outputId":"1bbbdec2-33e6-4bb3-ce62-6e0d2c03b578"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["_StoreAction(option_strings=['-f'], dest='f', nargs=None, const=None, default=None, type=None, choices=None, required=False, help=None, metavar=None)"]},"metadata":{},"execution_count":16}],"source":["parser.add_argument('-f')"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"BVYPeC_bBm4_","executionInfo":{"status":"ok","timestamp":1710087279054,"user_tz":-480,"elapsed":12,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["args = parser.parse_args()"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"qT2E7aBP94YS","executionInfo":{"status":"ok","timestamp":1710087279054,"user_tz":-480,"elapsed":12,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["# load checkpoint, these parameters can't be modified\n","final_args = {\"emb_dim\": 300, \"n_heads\": 8, \"dropout\": 0.1, \"encoder_layers\": 6}"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"k3p_qRlO9vRA","executionInfo":{"status":"ok","timestamp":1710087279054,"user_tz":-480,"elapsed":12,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["seed_everything()"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"VUVcmH4N-md_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710087279054,"user_tz":-480,"elapsed":12,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}},"outputId":"23da6a38-f7ff-4784-94b8-68d0277f7692"},"outputs":[{"output_type":"stream","name":"stdout","text":["device = cuda\n"]}],"source":["# GPU or CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n","cudnn.benchmark = True  # set to true only if inputs to model are fixed size; otherwise lot of computational overhead\n","print('device =', device)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"AtPTsnSQ-mgo","executionInfo":{"status":"ok","timestamp":1710087279054,"user_tz":-480,"elapsed":10,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["# best model initialize\n","start_epoch = 1\n","best_epoch = [0]\n","best_results = [0.0]\n","epochs_since_improvement = 0"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"bmnCO1QF-vyO","executionInfo":{"status":"ok","timestamp":1710087279055,"user_tz":-480,"elapsed":11,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["# tokenizer\n","tokenizer = None\n","tokenizer = BertTokenizer.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/research/multi-modality/t3_code\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Dd9-TLsuoji"},"outputs":[],"source":["tokenizer"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"D_UqbIWhzNge","executionInfo":{"status":"ok","timestamp":1710087279055,"user_tz":-480,"elapsed":9,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["args.num_class = 18"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"Pk_IIVHqzNge","executionInfo":{"status":"ok","timestamp":1710087281394,"user_tz":-480,"elapsed":2347,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["#if args.transformer_ver == 'vb':\n","model = VisualBertClassification(vocab_size=len(tokenizer), layers=6, n_heads=8, num_class = args.num_class)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"TQnFnWfWZ4H8","executionInfo":{"status":"ok","timestamp":1710087281394,"user_tz":-480,"elapsed":5,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"ZnXYJoVI0TD4","executionInfo":{"status":"ok","timestamp":1710087281394,"user_tz":-480,"elapsed":4,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["def str2list(target_str):\n","  res=target_str.strip('[')\n","  res=res.strip(']')\n","  res=res.split(',')\n","\n","  for i in range(len(res)):\n","    res[i] = res[i].strip() # 去掉空格\n","\n","  new_list = [float(x) for x in res]\n","  return new_list[:20]"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"hKinQRdVaJ5S","executionInfo":{"status":"ok","timestamp":1710087281394,"user_tz":-480,"elapsed":4,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["# training function for our CL algorithm\n","def train_daisi(args, train_dataloader, model, criterion, optimizer, epoch, tokenizer, device):\n","\n","    model.train()\n","\n","    total_loss = 0.0\n","    label_true = None\n","    label_pred = None\n","    label_score = None\n","\n","\n","    for i, (_, visual_features, q, labels, t5_loss) in enumerate(train_dataloader,0):\n","\n","        label_number = labels.numpy()[0]\n","\n","        # prepare questions\n","        questions = []\n","        for question in q: questions.append(question)\n","        inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n","\n","        # t5 loss\n","        t5_loss_list = []\n","        for j in range(len(t5_loss)):\n","          #tmp = str2list(t5_loss[j])\n","          tmp = t5_loss[j][:20]\n","          t5_loss_list.append(tmp)\n","        check = np.reciprocal(t5_loss_list)\n","        t5_loss_tensor = torch.tensor(check)\n","\n","        t5_loss_tensor = t5_loss_tensor.to(device)\n","\n","        # GPU / CPU\n","        visual_features = visual_features.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(inputs, visual_features)\n","        soft_target = model_old(inputs, visual_features)\n","\n","        loss1 = criterion(outputs, labels)\n","\n","        T=2\n","        outputs_S = F.softmax(outputs[:,:out_features]/T,dim=1)\n","        outputs_T = F.softmax(soft_target[:,:out_features]/T,dim=1)\n","\n","        outputs_t5_loss = F.softmax(t5_loss_tensor[:,:out_features]/T,dim=1)\n","\n","        loss2 = outputs_T.mul(-1*torch.log(outputs_S))\n","        loss2 = loss2.sum(1)\n","        loss2 = loss2.mean()*T*T\n","\n","        loss3 = outputs_t5_loss.mul(-1*torch.log(outputs_S))\n","        loss3 = loss3.sum(1)\n","        loss3 = loss3.mean()*T*T\n","\n","        loss = loss1 * acc_weight.at[label_number,'weight_true_label'] + loss2 * acc_weight.at[label_number,'weight_soft'] + loss3 * acc_weight.at[label_number,'weight_llm']\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        total_loss += loss.item()\n","\n","        scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)\n","        label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n","        label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n","        label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n","\n","    # loss and acc\n","    acc, c_acc = calc_acc(label_true, label_pred), calc_classwise_acc(label_true, label_pred)\n","    precision, recall, fscore = calc_precision_recall_fscore(label_true, label_pred)\n","    return acc"]},{"cell_type":"markdown","metadata":{"id":"pzqKlmoaNfZU"},"source":["# Imbalance Issue"]},{"cell_type":"code","source":["# Since the three dataset is already fixed, we pre-store the label distribution in a CSV file to save the time loading all the data\n","# Load all the data will be a VERY time-consuming in Colab\n","import math\n","N_Balance = 2000\n","\n","frequency_all = pd.read_csv(\"frequency_all.csv\")\n","tmp = frequency_all[frequency_all['18']!=0]\n","max_17_18_daisi=frequency_all['17+18+daisi'].max()\n","min_17_18_daisi = tmp['17+18+daisi'].min()\n","IR_17_18_daisi = max_17_18_daisi / min_17_18_daisi\n","ln_IR_17_18_daisi = math.log(IR_17_18_daisi,N_Balance)\n","print(ln_IR_17_18_daisi)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6SK1fSzW77XP","executionInfo":{"status":"ok","timestamp":1710087281395,"user_tz":-480,"elapsed":5,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}},"outputId":"144e03c2-995a-4fb8-e30b-d27a03d48549"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["0.49728056947874694\n"]}]},{"cell_type":"markdown","metadata":{"id":"Gu8egdk7hllm"},"source":["# Load DAISI-VQA dataset and the CL model trained on 17 and 18 dataset"]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","import torch\n","\n","class DaisiVQADataset(Dataset):\n","    def __init__(self, csv_file, data_type, patch_size=5):\n","        self.patch_size = patch_size\n","        tmp = pd.read_csv(csv_file)\n","        self.data_frame = tmp[tmp['type']==data_type]\n","\n","    def __len__(self):\n","        return len(self.data_frame)\n","\n","    def __getitem__(self, idx):\n","        sample = self.data_frame.iloc[idx]\n","        q = sample['q']\n","        labels = torch.tensor(sample['labels'])\n","        file_name = str(sample['path'])\n","\n","        visual_feature_loc = '/' + os.path.join('content/drive/MyDrive/Colab Notebooks/research/multi-modality/daisi_vqa_final/data/',file_name,'vqa/img_features',(str(self.patch_size)+'x'+str(self.patch_size)),file_name+'.hdf5')\n","        frame_data = h5py.File(visual_feature_loc, 'r')\n","        visual_features = torch.from_numpy(frame_data['visual_features'][:])\n","\n","        t5_loss = torch.tensor(eval(sample['t5_loss']))\n","\n","        return file_name, visual_features, q, labels, t5_loss"],"metadata":{"id":"QnZ9BLTQ7oL_","executionInfo":{"status":"ok","timestamp":1710087281912,"user_tz":-480,"elapsed":521,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["csv_file = '/content/drive/MyDrive/Colab Notebooks/research/multi-modality/daisi_vqa_final/daisi_data.csv'\n","\n","train_dataset = DaisiVQADataset(csv_file,'train',patch_size=5)\n","train_dataloader = DataLoader(dataset=train_dataset, batch_size=1, shuffle=True)\n","\n","val_dataset = DaisiVQADataset(csv_file,'val',patch_size=5)\n","val_dataloader = DataLoader(dataset=val_dataset, batch_size=1, shuffle=True)"],"metadata":{"id":"JWwp_Q-97tu-","executionInfo":{"status":"ok","timestamp":1710087281912,"user_tz":-480,"elapsed":2,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","execution_count":32,"metadata":{"id":"Yt_Kab9-hnU8","executionInfo":{"status":"ok","timestamp":1710087284176,"user_tz":-480,"elapsed":2266,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["# old model\n","checkpoint_old = torch.load('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/t3_code/checkpoints_all/OurMethod/Pretrain_t2.pth.tar')\n","model_old = checkpoint_old['model']"]},{"cell_type":"code","source":["# new model\n","checkpoint = torch.load('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/t3_code/checkpoints_all/OurMethod/Pretrain_t2.pth.tar')"],"metadata":{"id":"NrM0bjzLpxlq","executionInfo":{"status":"ok","timestamp":1710087287192,"user_tz":-480,"elapsed":3018,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["model = checkpoint['model']\n","optimizer = checkpoint['optimizer']"],"metadata":{"id":"3rMSc0fKp0aJ","executionInfo":{"status":"ok","timestamp":1710087287192,"user_tz":-480,"elapsed":7,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# change the last FC layer for new model (add the node for new classes)\n","num_new_class = 2\n","\n","def kaiming_normal_init(m):\n","\tif isinstance(m, nn.Conv2d):\n","\t\tnn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n","\telif isinstance(m, nn.Linear):\n","\t\tnn.init.kaiming_normal_(m.weight, nonlinearity='sigmoid')\n","\n","# Old number of input/output channel of the last FC layer in old model\n","in_features = model.classifier.in_features\n","out_features = model.classifier.out_features\n","\n","# Old weight/bias of the last FC layer\n","weight = model.classifier.weight.data\n","bias = model.classifier.bias.data\n","\n","# New number of output channel of the last FC layer in new model\n","new_out_features = num_new_class + out_features\n","\n","# Creat a new FC layer and initial it's weight/bias\n","new_fc = nn.Linear(in_features, new_out_features)\n","kaiming_normal_init(new_fc.weight)\n","new_fc.weight.data[:out_features] = weight\n","new_fc.bias.data[:out_features] = bias\n","\n","# Replace the old FC layer\n","model.classifier = new_fc"],"metadata":{"id":"OuOPTFIZp33y","executionInfo":{"status":"ok","timestamp":1710087287192,"user_tz":-480,"elapsed":6,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["model_old.classifier = new_fc"],"metadata":{"id":"z2U87zkJp6dz","executionInfo":{"status":"ok","timestamp":1710087287193,"user_tz":-480,"elapsed":7,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# Move to GPU, if available\n","model = model.to(device)\n","model_old = model_old.to(device)\n","print(final_args)\n","pytorch_total_params = sum(p.numel() for p in model.parameters())\n","print('model params: ', pytorch_total_params)"],"metadata":{"id":"b5OacAqwp87x","executionInfo":{"status":"ok","timestamp":1710087287193,"user_tz":-480,"elapsed":7,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"93280cd0-0420-4ee0-ac85-48f07bfeaf16"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["{'emb_dim': 300, 'n_heads': 8, 'dropout': 0.1, 'encoder_layers': 6}\n","model params:  184186900\n"]}]},{"cell_type":"code","source":["# Loss function\n","criterion = nn.CrossEntropyLoss().to(device)"],"metadata":{"id":"QvH_rzXjqBsH","executionInfo":{"status":"ok","timestamp":1710087287193,"user_tz":-480,"elapsed":6,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["args.checkpoint_dir = '/content/drive/MyDrive/Colab Notebooks/research/multi-modality/t3_code/checkpoints_all/OurMethod/'"],"metadata":{"id":"rHhuCnWLqDqw","executionInfo":{"status":"ok","timestamp":1710087287193,"user_tz":-480,"elapsed":5,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# best model initialize\n","start_epoch = 1\n","best_epoch = [0]\n","best_results = [0.0]\n","epochs_since_improvement = 0"],"metadata":{"id":"q-9QWfC6qGQ6","executionInfo":{"status":"ok","timestamp":1710087287193,"user_tz":-480,"elapsed":5,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["out_features = model.classifier.out_features"],"metadata":{"id":"yAXFM13TqIu7","executionInfo":{"status":"ok","timestamp":1710087287193,"user_tz":-480,"elapsed":5,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dMR0b-DrzNgs"},"source":["## soft target和大模型准确率"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"VGftJ3ppzNgs","executionInfo":{"status":"ok","timestamp":1710087293791,"user_tz":-480,"elapsed":6603,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["label = []\n","label_soft_list = []\n","\n","for i, (_, visual_features, q, labels, t5_loss) in enumerate(train_dataloader,0):\n","\n","    label_number = labels.numpy()[0]\n","\n","    label += labels.tolist()\n","\n","    # prepare questions\n","    questions = []\n","    for question in q: questions.append(question)\n","\n","    inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n","\n","    # GPU / CPU\n","    visual_features = visual_features.to(device)\n","    labels = labels.to(device)\n","\n","    soft_target = model_old(inputs, visual_features)\n","    output_class_ranks = torch.argsort(soft_target, dim=-1, descending=True)\n","\n","    label_soft = []\n","    for j in range(len(output_class_ranks)):\n","        label_soft.append(int(output_class_ranks[j][0]))\n","\n","    label_soft_list += label_soft"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"tZxvyCKNzNgt","scrolled":true,"executionInfo":{"status":"ok","timestamp":1710087293792,"user_tz":-480,"elapsed":3,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6604c1c6-df84-4eee-9384-12d70caf5771"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n","  avg = a.mean(axis, **keepdims_kw)\n","/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n","  ret = ret.dtype.type(ret / rcount)\n","/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n","  avg = a.mean(axis, **keepdims_kw)\n","/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n","  ret = ret.dtype.type(ret / rcount)\n","/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n","  avg = a.mean(axis, **keepdims_kw)\n","/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n","  ret = ret.dtype.type(ret / rcount)\n","/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n","  avg = a.mean(axis, **keepdims_kw)\n","/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n","  ret = ret.dtype.type(ret / rcount)\n","/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n","  avg = a.mean(axis, **keepdims_kw)\n","/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n","  ret = ret.dtype.type(ret / rcount)\n","/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n","  avg = a.mean(axis, **keepdims_kw)\n","/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n","  ret = ret.dtype.type(ret / rcount)\n","/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n","  avg = a.mean(axis, **keepdims_kw)\n","/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n","  ret = ret.dtype.type(ret / rcount)\n","/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n","  avg = a.mean(axis, **keepdims_kw)\n","/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n","  ret = ret.dtype.type(ret / rcount)\n","/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n","  avg = a.mean(axis, **keepdims_kw)\n","/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n","  ret = ret.dtype.type(ret / rcount)\n","/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n","  avg = a.mean(axis, **keepdims_kw)\n","/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n","  ret = ret.dtype.type(ret / rcount)\n","/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n","  avg = a.mean(axis, **keepdims_kw)\n","/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n","  ret = ret.dtype.type(ret / rcount)\n","/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n","  avg = a.mean(axis, **keepdims_kw)\n","/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n","  ret = ret.dtype.type(ret / rcount)\n","/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n","  avg = a.mean(axis, **keepdims_kw)\n","/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n","  ret = ret.dtype.type(ret / rcount)\n"]}],"source":["from pandas.core.frame import DataFrame\n","from sklearn.metrics import accuracy_score\n","import math\n","\n","c={\"label\" : label,\n","   \"label_soft_list\" : label_soft_list}\n","data=DataFrame(c)\n","\n","acc_soft = []\n","\n","for i in range(20):\n","    label_part = []\n","    label_soft_part = []\n","\n","    for j in range(len(data)):\n","        if data.at[j,'label'] == i:\n","            label_part.append(data.at[j,'label'])\n","            label_soft_part.append(data.at[j,'label_soft_list'])\n","\n","    acc_soft.append(accuracy_score(label_part, label_soft_part))\n","acc_soft = [0 if math.isnan(x) else x for x in acc_soft]"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"Pgfeue9kzNgt","executionInfo":{"status":"ok","timestamp":1710087295564,"user_tz":-480,"elapsed":1774,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["label = []\n","label_llm_list = []\n","\n","for i, (_, visual_features, q, labels, t5_loss) in enumerate(train_dataloader,0):\n","  label += labels.tolist()\n","\n","  t5_loss_list = []\n","  for j in range(len(t5_loss)):\n","    #tmp = str2list(t5_loss[j])\n","    tmp = t5_loss[j][:20]\n","    t5_loss_list.append(tmp)\n","\n","  check = np.reciprocal(t5_loss_list)\n","  t5_loss_tensor = torch.tensor(check)\n","  output_class_ranks = torch.argsort(t5_loss_tensor, dim=-1, descending=True)\n","\n","  label_llm = []\n","  for j in range(len(output_class_ranks)):\n","    label_llm.append(int(output_class_ranks[j][0]))\n","\n","  label_llm_list += label_llm"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"4ABdUznczNgt","executionInfo":{"status":"ok","timestamp":1710087295565,"user_tz":-480,"elapsed":6,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["c={\"label\" : label,\n","   \"label_llm_list\" : label_llm_list}\n","data=DataFrame(c)\n","\n","acc_llm = []\n","\n","for i in range(20):\n","  label_part = []\n","  label_llm_part = []\n","\n","  for j in range(len(data)):\n","    if data.at[j,'label'] == i:\n","      label_part.append(data.at[j,'label'])\n","      label_llm_part.append(data.at[j,'label_llm_list'])\n","\n","  if len(label_part) == 0:\n","    acc_llm.append(0)\n","  else:\n","    acc_llm.append(accuracy_score(label_part, label_llm_part))\n","\n","acc_llm = [0 if math.isnan(x) else x for x in acc_llm]"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"F2z4Gb-bzNgu","executionInfo":{"status":"ok","timestamp":1710087295565,"user_tz":-480,"elapsed":5,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["c={\"acc_soft\" : acc_soft,\n","   \"acc_llm\" : acc_llm}\n","weight_data_17_18_daisi=DataFrame(c)\n","\n","hard_label_weight=0.2\n","for i in range(len(weight_data_17_18_daisi)):\n","  if weight_data_17_18_daisi.at[i,'acc_soft'] + weight_data_17_18_daisi.at[i,'acc_llm'] == 0:\n","    weight_data_17_18_daisi.at[i,'DS_soft'] = 0.5*(1 - hard_label_weight)\n","    weight_data_17_18_daisi.at[i,'DS_llm'] = 0.5*(1 - hard_label_weight)\n","  else:\n","    weight_data_17_18_daisi.at[i,'DS_soft'] = (1-hard_label_weight) * weight_data_17_18_daisi.at[i,'acc_soft'] / (weight_data_17_18_daisi.at[i,'acc_soft'] + weight_data_17_18_daisi.at[i,'acc_llm'])\n","    weight_data_17_18_daisi.at[i,'DS_llm'] = (1-hard_label_weight) * weight_data_17_18_daisi.at[i,'acc_llm'] / (weight_data_17_18_daisi.at[i,'acc_soft'] + weight_data_17_18_daisi.at[i,'acc_llm'])"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"0ReGsggkzNgu","executionInfo":{"status":"ok","timestamp":1710087295565,"user_tz":-480,"elapsed":5,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}}},"outputs":[],"source":["#weight processing\n","DS_weight=0.2\n","DI_weight=0.8\n","weight_data_17_18_daisi['DI_soft']=(1-hard_label_weight) * (1 / (1 + ln_IR_17_18_daisi))\n","weight_data_17_18_daisi['DI_llm'] = (1-hard_label_weight) * ((ln_IR_17_18_daisi) / (1 + ln_IR_17_18_daisi))\n","weight_data_17_18_daisi['weight_true_label']=hard_label_weight\n","weight_data_17_18_daisi['weight_soft'] = DS_weight * weight_data_17_18_daisi['DS_soft'] + DI_weight * weight_data_17_18_daisi['DI_soft']\n","weight_data_17_18_daisi['weight_llm'] = DS_weight * weight_data_17_18_daisi['DS_llm'] + DI_weight * weight_data_17_18_daisi['DI_llm']"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"DUrJwYy1zNgu","executionInfo":{"status":"ok","timestamp":1710087295565,"user_tz":-480,"elapsed":5,"user":{"displayName":"kexin chen","userId":"10371452033462374396"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"67f14118-0dd7-43dc-ec8e-2fe5270996f5"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-48-2fa82b5046a2>:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n","  acc_weight.weight_data_17_18_daisi = ['weight_true_label','weight_soft','weight_llm']\n"]}],"source":["acc_weight = weight_data_17_18_daisi[['weight_true_label','weight_soft','weight_llm']]\n","acc_weight.weight_data_17_18_daisi = ['weight_true_label','weight_soft','weight_llm']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PADLc933l9jR"},"outputs":[],"source":["for epoch in range(start_epoch, 80):\n","  if epochs_since_improvement > 0 and epochs_since_improvement % 5 == 0:\n","    adjust_learning_rate(optimizer, 0.8)\n","\n","  # train\n","  train_acc = train_daisi(args, train_dataloader=train_dataloader, model = model, criterion=criterion, optimizer=optimizer, epoch=epoch, tokenizer = tokenizer, device = device)\n","\n","  # validation\n","  test_acc, test_c_acc, test_precision, test_recall, test_fscore = validate_18(args, val_loader=val_dataloader, model = model, criterion=criterion, epoch=epoch, tokenizer = tokenizer, device = device)\n","\n","  if test_acc >= best_results[0]:\n","    epochs_since_improvement = 0\n","\n","    best_results[0] = test_acc\n","    best_epoch[0] = epoch\n","    save_clf_checkpoint(args.checkpoint_dir, epoch, epochs_since_improvement, model, optimizer, best_results[0], final_args)\n","\n","  else:\n","    epochs_since_improvement += 1\n","\n","  if train_acc >= 1.0: break"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"pytorch","language":"python","name":"pytorch"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}